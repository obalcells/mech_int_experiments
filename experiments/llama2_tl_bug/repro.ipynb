{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"4,5\"\n",
    "import gc\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformer_lens import HookedTransformer\n",
    "from transformer_lens import utils as tl_utils\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import einops\n",
    "from jaxtyping import Int, Float\n",
    "from torch import Tensor\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import functools\n",
    "from typing import Dict, Optional, Tuple, Union\n",
    "from jaxtyping import Float, Int\n",
    "from transformer_lens.HookedTransformerConfig import HookedTransformerConfig\n",
    "from transformer_lens.hook_points import HookedRootModule, HookPoint\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'allocated_bytes.all.current'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/home/obalcells/a23-jailbreaks-obalcells/experiments/llama2_tl_bug/repro.ipynb Cell 2\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bprivsec0.inf.ethz.ch/home/obalcells/a23-jailbreaks-obalcells/experiments/llama2_tl_bug/repro.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mempty_cache()\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bprivsec0.inf.ethz.ch/home/obalcells/a23-jailbreaks-obalcells/experiments/llama2_tl_bug/repro.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mfor\u001b[39;00m device \u001b[39min\u001b[39;00m devices:\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bprivsec0.inf.ethz.ch/home/obalcells/a23-jailbreaks-obalcells/experiments/llama2_tl_bug/repro.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m     \u001b[39mprint\u001b[39m(torch\u001b[39m.\u001b[39;49mcuda\u001b[39m.\u001b[39;49mmemory_summary(device\u001b[39m=\u001b[39;49mdevice))\n",
      "File \u001b[0;32m/local/home/obalcells/miniforge3/envs/jailbreak/lib/python3.11/site-packages/torch/cuda/memory.py:557\u001b[0m, in \u001b[0;36mmemory_summary\u001b[0;34m(device, abbreviated)\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[39mfor\u001b[39;00m submetric_key, submetric_name \u001b[39min\u001b[39;00m submetrics:\n\u001b[1;32m    555\u001b[0m     prefix \u001b[39m=\u001b[39m metric_key \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m submetric_key \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 557\u001b[0m     current \u001b[39m=\u001b[39m stats[prefix \u001b[39m+\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mcurrent\u001b[39;49m\u001b[39m\"\u001b[39;49m]\n\u001b[1;32m    558\u001b[0m     peak \u001b[39m=\u001b[39m stats[prefix \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpeak\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    559\u001b[0m     allocated \u001b[39m=\u001b[39m stats[prefix \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mallocated\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "\u001b[0;31mKeyError\u001b[0m: 'allocated_bytes.all.current'"
     ]
    }
   ],
   "source": [
    "device_ids = [0, 1]\n",
    "devices = [torch.device(f\"cuda:{i}\") for i in device_ids]\n",
    "torch.cuda.empty_cache()\n",
    "for device in devices:\n",
    "    print(torch.cuda.memory_summary(device=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    1, 15043,   891, 29901]])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    tokens = tl_model.tokenizer.encode(\"Hello |:\", return_tensors=\"pt\")\n",
    "    print(tokens.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_similarity_with_hf_model(\n",
    "    tl_model: HookedTransformer,\n",
    "    hf_model: AutoModelForCausalLM,\n",
    "    atol: float,\n",
    "    prompt=\"Hello world!\",\n",
    "):\n",
    "    tokens = tl_model.tokenizer.encode(prompt, return_tensors=\"pt\")\n",
    "    hf_logits = hf_model(tokens.to(devices[0])).logits\n",
    "    tl_logits = tl_model(tokens.to(devices[1]), prepend_bos=False)\n",
    "    assert torch.allclose(tl_logits.cpu(), hf_logits.cpu(), atol=atol), \"Numerical error too large\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de5d3dc0df8b41eaa707ae41dbc99714",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MODEL_NAME = \"meta-llama/Llama-2-7b-chat-hf\"\n",
    "\n",
    "hf_model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    low_cpu_mem_usage=True,\n",
    "    torch_dtype=torch.float32,\n",
    ").to(devices[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9267ec2df7cf48bf927ef85ee6cb1164",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model meta-llama/Llama-2-7b-chat-hf into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "tl_model = HookedTransformer.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    hf_model=AutoModelForCausalLM.from_pretrained(\n",
    "        MODEL_NAME,\n",
    "        low_cpu_mem_usage=True,\n",
    "        torch_dtype=torch.float32,\n",
    "    ),\n",
    "    tokenizer=AutoTokenizer.from_pretrained(MODEL_NAME),\n",
    "    device=devices[1],\n",
    "    n_devices=1,\n",
    "    move_to_device=True,\n",
    "    fold_ln=False,\n",
    "    fold_value_biases=False,\n",
    "    center_writing_weights=False,\n",
    "    center_unembed=False,\n",
    "    torch_dtype=torch.float32,\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/obalcells/a23-jailbreaks-obalcells/experiments/llama2_tl_bug/repro.ipynb Cell 6\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bprivsec0.inf.ethz.ch/home/obalcells/a23-jailbreaks-obalcells/experiments/llama2_tl_bug/repro.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bprivsec0.inf.ethz.ch/home/obalcells/a23-jailbreaks-obalcells/experiments/llama2_tl_bug/repro.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m     check_similarity_with_hf_model(tl_model, hf_model, atol\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n",
      "\u001b[1;32m/home/obalcells/a23-jailbreaks-obalcells/experiments/llama2_tl_bug/repro.ipynb Cell 6\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bprivsec0.inf.ethz.ch/home/obalcells/a23-jailbreaks-obalcells/experiments/llama2_tl_bug/repro.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m hf_logits \u001b[39m=\u001b[39m hf_model(tokens\u001b[39m.\u001b[39mto(devices[\u001b[39m0\u001b[39m]))\u001b[39m.\u001b[39mlogits\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bprivsec0.inf.ethz.ch/home/obalcells/a23-jailbreaks-obalcells/experiments/llama2_tl_bug/repro.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m tl_logits \u001b[39m=\u001b[39m tl_model(tokens\u001b[39m.\u001b[39mto(devices[\u001b[39m1\u001b[39m]), prepend_bos\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bprivsec0.inf.ethz.ch/home/obalcells/a23-jailbreaks-obalcells/experiments/llama2_tl_bug/repro.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39massert\u001b[39;00m torch\u001b[39m.\u001b[39mallclose(tl_logits\u001b[39m.\u001b[39mcpu(), hf_logits\u001b[39m.\u001b[39mcpu(), atol\u001b[39m=\u001b[39matol)\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    check_similarity_with_hf_model(tl_model, hf_model, atol=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# before running this we've replaced ln1 and ln2 at each layer with the corresponding ln in the HF model\n",
    "with torch.no_grad():\n",
    "    check_similarity_with_hf_model(tl_model, hf_model, atol=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttnWrapper(torch.nn.Module):\n",
    "    def __init__(self, attn):\n",
    "        super().__init__()\n",
    "        self.attn = attn\n",
    "        self.save_activations = False \n",
    "        self.activations = None\n",
    "\n",
    "    def forward(self, *args, **kwargs):\n",
    "        output = self.attn(*args, **kwargs)\n",
    "        if self.save_activations:\n",
    "            self.activations = output[0]\n",
    "        return output\n",
    "\n",
    "class BlockOutputWrapper(torch.nn.Module):\n",
    "    def __init__(self, block, unembed_matrix, norm):\n",
    "        super().__init__()\n",
    "        self.block = block\n",
    "        self.unembed_matrix = unembed_matrix\n",
    "        self.norm = norm\n",
    "\n",
    "        self.block.self_attn = AttnWrapper(self.block.self_attn)\n",
    "        self.post_attention_layernorm = self.block.post_attention_layernorm\n",
    "\n",
    "        self.attn_out_unembedded = None\n",
    "        self.intermediate_resid_unembedded = None\n",
    "        self.mlp_out_unembedded = None\n",
    "        self.block_out_unembedded = None\n",
    "\n",
    "        self.activations = None\n",
    "\n",
    "        self.save_activations = False\n",
    "        self.save_internal_decodings = False\n",
    "\n",
    "\n",
    "    def forward(self, *args, **kwargs):\n",
    "        output = self.block(*args, **kwargs)\n",
    "        activations: Float[Tensor, \"batch_size seq_len d_model\"] = output[0]\n",
    "\n",
    "        if self.save_activations:\n",
    "            self.activations = activations\n",
    "\n",
    "        return output\n",
    "\n",
    "    def reset(self):\n",
    "        self.activations = None\n",
    "        self.block.self_attn.activations = None\n",
    "\n",
    "\n",
    "class Llama2Wrapper:\n",
    "    def __init__(self, hf_model):\n",
    "        self.wrapped_model = hf_model\n",
    "\n",
    "        for i, layer in enumerate(self.wrapped_model.model.layers):\n",
    "            self.wrapped_model.model.layers[i] = BlockOutputWrapper(\n",
    "                layer, self.wrapped_model.lm_head, self.wrapped_model.model.norm\n",
    "            )\n",
    "\n",
    "    def set_save_activations(self, value, layers=None):\n",
    "        if layers is None:\n",
    "            for layer in self.wrapped_model.model.layers:\n",
    "                layer.save_activations = value\n",
    "                layer.block.self_attn.save_activations = value\n",
    "        elif isinstance(layers, int):\n",
    "            self.wrapped_model.model.layers[layers].save_activations = value\n",
    "            self.wrapped_model.model.layers[layers].block.self_attn.save_activations = value\n",
    "        elif isinstance(layers[0], int):\n",
    "            for layer in layers:\n",
    "                self.wrapped_model.model.layers[layer].save_activations = value\n",
    "                self.wrapped_model.model.layers[layer].block.self_attn.save_activations = value\n",
    "        else:\n",
    "            assert False, \"Incorrect input arguments to set_save_activations function\"\n",
    "\n",
    "    def set_save_internal_decodings(self, value):\n",
    "        for layer in self.wrapped_model.model.layers:\n",
    "            layer.save_internal_decodings = value\n",
    "\n",
    "    def get_logits(self, tokens):\n",
    "        with torch.no_grad():\n",
    "            logits = self.wrapped_model(tokens).logits\n",
    "            return logits\n",
    "\n",
    "    def get_last_activations(self, layer):\n",
    "        return self.wrapped_model.model.layers[layer].activations\n",
    "\n",
    "    def reset_all(self):\n",
    "        for layer in self.wrapped_model.model.layers:\n",
    "            layer.reset()\n",
    "\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        return self.wrapped_model(*args, **kwargs)\n",
    "\n",
    "    def unwrap(self):\n",
    "        for i, layer in enumerate(self.wrapped_model.model.layers):\n",
    "            self.wrapped_model.model.layers[i] = layer.block\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_wrapped_model = Llama2Wrapper(hf_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/obalcells/a23-jailbreaks-obalcells/experiments/llama2_tl_bug/repro.ipynb Cell 9\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bprivsec0.inf.ethz.ch/home/obalcells/a23-jailbreaks-obalcells/experiments/llama2_tl_bug/repro.ipynb#X33sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bprivsec0.inf.ethz.ch/home/obalcells/a23-jailbreaks-obalcells/experiments/llama2_tl_bug/repro.ipynb#X33sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m     check_similarity_with_hf_model(tl_model, hf_wrapped_model, atol\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n",
      "\u001b[1;32m/home/obalcells/a23-jailbreaks-obalcells/experiments/llama2_tl_bug/repro.ipynb Cell 9\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bprivsec0.inf.ethz.ch/home/obalcells/a23-jailbreaks-obalcells/experiments/llama2_tl_bug/repro.ipynb#X33sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m hf_logits \u001b[39m=\u001b[39m hf_model(tokens\u001b[39m.\u001b[39mto(devices[\u001b[39m0\u001b[39m]))\u001b[39m.\u001b[39mlogits\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bprivsec0.inf.ethz.ch/home/obalcells/a23-jailbreaks-obalcells/experiments/llama2_tl_bug/repro.ipynb#X33sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m tl_logits \u001b[39m=\u001b[39m tl_model(tokens\u001b[39m.\u001b[39mto(devices[\u001b[39m1\u001b[39m]), prepend_bos\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bprivsec0.inf.ethz.ch/home/obalcells/a23-jailbreaks-obalcells/experiments/llama2_tl_bug/repro.ipynb#X33sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39massert\u001b[39;00m torch\u001b[39m.\u001b[39mallclose(tl_logits\u001b[39m.\u001b[39mcpu(), hf_logits\u001b[39m.\u001b[39mcpu(), atol\u001b[39m=\u001b[39matol)\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    check_similarity_with_hf_model(tl_model, hf_wrapped_model, atol=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    check_similarity_with_hf_model(tl_model, hf_wrapped_model, atol=1.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the error at different layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_error_layer(layer):\n",
    "    hf_wrapped_model.reset_all()\n",
    "    hf_wrapped_model.set_save_activations(True, layer)\n",
    "    hf_wrapped_model.set_save_internal_decodings(True)\n",
    "\n",
    "    tokens = tl_model.tokenizer.encode(\"Hello world!\", return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        hf_logits = hf_wrapped_model.get_logits(tokens.to(devices[0]))\n",
    "        hf_activations = hf_wrapped_model.get_last_activations(layer)\n",
    "        print(\"HF activations\", hf_activations[0, 0, :10])\n",
    "\n",
    "    tl_activations = torch.zeros_like(hf_activations, device=devices[1])\n",
    "\n",
    "    def hook_fn(activations, hook):\n",
    "        tl_activations = activations\n",
    "        print(\"TL activations\", activations[0, 0, :10])\n",
    "    \n",
    "    hook_filter = lambda name: name.startswith(f\"blocks.{layer}.hook_resid_post\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        tl_model.run_with_hooks(\n",
    "            tokens.to(devices[1]),\n",
    "            prepend_bos=False,\n",
    "            fwd_hooks=[(hook_filter, hook_fn)],\n",
    "        )\n",
    "\n",
    "    diff = torch.abs(tl_activations.cpu() - hf_activations.cpu())\n",
    "    print(\"Diff\", diff[0, 0, :10])\n",
    "    print(\"Max difference\", diff.max().item())\n",
    "    print(\"Max difference in last token position\", diff[0,-1,:].max().item())\n",
    "    print(\"Mean difference in the last token position\", diff[-1,-1,:].mean().item())\n",
    "    print(\"Mean difference in first token position\", diff[-1,0,:].mean().item())\n",
    "\n",
    "    hf_wrapped_model.set_save_activations(False)\n",
    "    hf_wrapped_model.set_save_internal_decodings(False)\n",
    "    hf_wrapped_model.reset_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'check_error_layer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/obalcells/a23-jailbreaks-obalcells/experiments/llama2_tl_bug/repro.ipynb Cell 13\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bprivsec0.inf.ethz.ch/home/obalcells/a23-jailbreaks-obalcells/experiments/llama2_tl_bug/repro.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m check_error_layer(\u001b[39m0\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'check_error_layer' is not defined"
     ]
    }
   ],
   "source": [
    "check_error_layer(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations:\n",
    "\n",
    "- The TL model seems to consume about 0.5 GB more of GPU memory\n",
    "```\n",
    " Device 1 [NVIDIA RTX A6000] PCIe GEN 1@16x RX: 0.000 KiB/s TX: 0.977 MiB/s\n",
    " GPU 210MHz  MEM 405MHz  TEMP  42°C FAN  30% POW  26 / 300 W\n",
    " GPU[                              0%] MEM[||||||||||||||25.965Gi/47.988Gi]\n",
    " Device 2 [NVIDIA RTX A6000] PCIe GEN 1@16x RX: 1.953 MiB/s TX: 0.000 KiB/s\n",
    " GPU 210MHz  MEM 405MHz  TEMP  42°C FAN  30% POW  22 / 300 W\n",
    " GPU[                              1%] MEM[||||||||||||||26.472Gi/47.988Gi]\n",
    "```\n",
    "- Assert triggered with atol=1.0 but not with atol=1.4\n",
    "- Extremely big imprecision at hook_resid_post even at early layers\n",
    "    - Max difference `activations_layer_2[0,0,:].max() = 758.8073120117188`\n",
    "    - Max difference in `activations_layer_2[0,-1,:].max() = 0.8543080687522888`\n",
    "    - Mean difference in `activations_layer_2[0,-1,:].max() = 0.8543080687522888`\n",
    "    - Mean difference `activations_layer_2[0,-1,:].mean() = 0.03889806941151619`\n",
    "    - Mean difference `activations_layer_2[0,0,:].mean() = 0.6288346648216248`\n",
    "- Even at layer 0?!?\n",
    "    - Max difference 4.763709545135498\n",
    "    - Max difference in last token position 1.8098640441894531\n",
    "    - Mean difference in the last token position 0.02045099064707756\n",
    "    - Mean difference in first token position 0.06380023807287216"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the earliest part where the differences occur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BlockOutputWrapper(torch.nn.Module):\n",
    "    def __init__(self, block, unembed_matrix, norm):\n",
    "        super().__init__()\n",
    "        self.block = block\n",
    "        self.unembed_matrix = unembed_matrix\n",
    "        self.norm = norm\n",
    "\n",
    "        self.block.self_attn = AttnWrapper(self.block.self_attn)\n",
    "        self.post_attention_layernorm = self.block.post_attention_layernorm\n",
    "\n",
    "        self.attn_out_unembedded = None\n",
    "        self.intermediate_resid_unembedded = None\n",
    "        self.mlp_out_unembedded = None\n",
    "        self.block_out_unembedded = None\n",
    "\n",
    "        self.activations = None\n",
    "\n",
    "        self.save_activations = False\n",
    "        self.save_internal_decodings = False\n",
    "\n",
    "    def forward(self, *args, **kwargs):\n",
    "        # print(kwargs.keys())\n",
    "        # print(args[0].shape)\n",
    "        if self.save_activations:\n",
    "            self.activations = args[0]\n",
    "        output = self.block(*args, **kwargs)\n",
    "        activations: Float[Tensor, \"batch_size seq_len d_model\"] = output[0]\n",
    "        # if self.save_activations:\n",
    "        #     self.activations = activations\n",
    "        return output\n",
    "\n",
    "    def reset(self):\n",
    "        self.activations = None\n",
    "        self.block.self_attn.activations = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Llama2Wrapper' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/obalcells/a23-jailbreaks-obalcells/experiments/llama2_tl_bug/repro.ipynb Cell 17\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bprivsec0.inf.ethz.ch/home/obalcells/a23-jailbreaks-obalcells/experiments/llama2_tl_bug/repro.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m#hf_wrapped_model.unwrap()\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bprivsec0.inf.ethz.ch/home/obalcells/a23-jailbreaks-obalcells/experiments/llama2_tl_bug/repro.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m hf_wrapped_model \u001b[39m=\u001b[39m Llama2Wrapper(hf_model)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Llama2Wrapper' is not defined"
     ]
    }
   ],
   "source": [
    "#hf_wrapped_model.unwrap()\n",
    "hf_wrapped_model = Llama2Wrapper(hf_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_error_layer_resid_pre(layer, atol=1.0):\n",
    "    hf_wrapped_model.reset_all()\n",
    "    hf_wrapped_model.set_save_activations(True, layer)\n",
    "    hf_wrapped_model.set_save_internal_decodings(True)\n",
    "\n",
    "    tokens = tl_model.tokenizer.encode(\"Hello world!\", return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        hf_logits = hf_wrapped_model.get_logits(tokens.to(devices[0]))\n",
    "        hf_activations = hf_wrapped_model.get_last_activations(layer)\n",
    "        # print(\"HF activations\", hf_activations[0, 0, :10])\n",
    "\n",
    "    tl_activations_ = torch.zeros_like(hf_activations, device=\"cpu\")\n",
    "\n",
    "    def hook_fn(activations, hook):\n",
    "        tl_activations_ = activations.clone().cpu()\n",
    "        # print(\"TL activations\", activations[0, 0, :10])\n",
    "    \n",
    "    hook_filter = lambda name: name.startswith(f\"blocks.{layer}.hook_resid_pre\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        tl_model.run_with_hooks(\n",
    "            tokens.to(devices[1]),\n",
    "            prepend_bos=False,\n",
    "            fwd_hooks=[(hook_filter, hook_fn)],\n",
    "        )\n",
    "\n",
    "    diff_ = torch.abs(tl_activations_ - hf_activations.cpu())\n",
    "\n",
    "    mean_diff = diff_.mean().item()\n",
    "    std_diff = diff_.std().item()\n",
    "    max_diff = diff_.max().item()\n",
    "\n",
    "    print(f\"Mean diff: {mean_diff:.3f}, std diff: {std_diff:.3f}, max diff: {max_diff:.3f}\")\n",
    "\n",
    "    # print(\"Diff\", diff_[0,0,:10])\n",
    "    # print(\"Initial mean difference\", diff_[0,0,:10].mean().item())\n",
    "    # print(\"Max difference\", diff_.max().item())\n",
    "    # print(\"Max difference in last token position\", diff_[0,-1,:].max().item())\n",
    "    # print(\"Mean difference in the last token position\", diff_[-1,-1,:].mean().item())\n",
    "    # print(\"Mean difference in first token position\", diff_[-1,0,:].mean().item())\n",
    "\n",
    "    hf_wrapped_model.set_save_activations(False)\n",
    "    hf_wrapped_model.set_save_internal_decodings(False)\n",
    "    hf_wrapped_model.reset_all()\n",
    "\n",
    "    return mean_diff, std_diff, max_diff\n",
    "\n",
    "    # assert torch.allclose(tl_activations_.cpu(), hf_activations.cpu(), atol=atol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean diff: 0.032, std diff: 0.068, max diff: 4.764\n",
      "Mean diff: 0.182, std diff: 6.896, max diff: 754.642\n",
      "Mean diff: 0.189, std diff: 6.934, max diff: 758.807\n",
      "Mean diff: 0.202, std diff: 6.935, max diff: 758.917\n",
      "Mean diff: 0.234, std diff: 7.001, max diff: 766.477\n",
      "Mean diff: 0.246, std diff: 7.002, max diff: 766.606\n",
      "Mean diff: 0.260, std diff: 7.002, max diff: 766.675\n",
      "Mean diff: 0.275, std diff: 7.002, max diff: 766.750\n",
      "Mean diff: 0.292, std diff: 7.002, max diff: 766.798\n",
      "Mean diff: 0.307, std diff: 7.003, max diff: 767.036\n",
      "Mean diff: 0.323, std diff: 7.003, max diff: 767.103\n",
      "Mean diff: 0.333, std diff: 7.004, max diff: 767.378\n",
      "Mean diff: 0.348, std diff: 7.006, max diff: 767.737\n",
      "Mean diff: 0.364, std diff: 7.009, max diff: 768.382\n",
      "Mean diff: 0.392, std diff: 7.010, max diff: 768.585\n",
      "Mean diff: 0.435, std diff: 7.012, max diff: 768.893\n",
      "Mean diff: 0.446, std diff: 7.037, max diff: 772.978\n",
      "Mean diff: 0.474, std diff: 7.040, max diff: 773.291\n",
      "Mean diff: 0.507, std diff: 7.042, max diff: 773.628\n",
      "Mean diff: 0.527, std diff: 7.043, max diff: 774.492\n",
      "Mean diff: 0.555, std diff: 7.045, max diff: 774.612\n",
      "Mean diff: 0.594, std diff: 7.050, max diff: 774.960\n",
      "Mean diff: 0.624, std diff: 7.056, max diff: 775.449\n",
      "Mean diff: 0.643, std diff: 7.060, max diff: 775.765\n",
      "Mean diff: 0.679, std diff: 7.065, max diff: 775.727\n",
      "Mean diff: 0.702, std diff: 7.066, max diff: 775.576\n",
      "Mean diff: 0.743, std diff: 7.072, max diff: 775.436\n",
      "Mean diff: 0.790, std diff: 7.070, max diff: 774.749\n",
      "Mean diff: 0.833, std diff: 7.072, max diff: 774.028\n",
      "Mean diff: 0.886, std diff: 7.042, max diff: 770.158\n",
      "Mean diff: 0.911, std diff: 3.752, max diff: 400.935\n",
      "Mean diff: 1.200, std diff: 2.055, max diff: 149.444\n"
     ]
    }
   ],
   "source": [
    "mean_diffs = []\n",
    "std_diffs = []\n",
    "max_diffs = []\n",
    "\n",
    "for i in range(32):\n",
    "    mean_diff, std_diff, max_diff = check_error_layer_resid_pre(i, atol=1.0)\n",
    "    mean_diffs.append(mean_diff)\n",
    "    std_diffs.append(std_diff)\n",
    "    max_diffs.append(max_diff)\n",
    "\n",
    "# plot the results using matplotlib in the same figure with legends\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAnYAAAHWCAYAAAD6oMSKAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/SrBM8AAAACXBIWXMAAA9hAAAPYQGoP6dpAABHK0lEQVR4nO3deViVdf7/8dcB2Q1cQVEE9z1STAdbLEPcQq1GTU3MytKk0ZgWaaPG77hkmvMt07TUpnHLUrMxddS0pqTMhczJXEqycQGXAIUEhc/vj36cr0e2c1A5ePd8XNe5Ls997vd9v+/D7eHF516OzRhjBAAAgGueh7sbAAAAwJVBsAMAALAIgh0AAIBFEOwAAAAsgmAHAABgEQQ7AAAAiyDYAQAAWATBDgAAwCIIdgAAABZBsANwVd12221q167dVV+PzWbTiy++eNXXA0f333+/IiIiyp0vLS1NNptNCxcuvOo9Ab9nBDvgGrFw4ULZbLZSH19++aW7W8RVNmnSJK1atcrdbQCowqq5uwEArvnLX/6ixo0bF5verFkzN3SDyjRp0iT98Y9/1IABA9zdit28efNUWFjo7jYA/H8EO+Aa07t3b3Xq1MmlmgsXLqiwsFDe3t7FXsvJyVFAQECF+zHG6Ny5c/Lz86vwMqzu3Llz8vb2loeHew+SXI0+vLy8rtiyLhf7IsChWMByis5leuWVVzRz5kw1bdpUPj4++u677/Tiiy/KZrPpu+++09ChQ1WzZk3dfPPNkn4LfxMnTrTPHxERoWeeeUZ5eXkOy4+IiNCdd96p9evXq1OnTvLz89Obb75Zbl87duxQ165d5efnp8aNG2vOnDn2186ePauAgACNGzeuWN1///tfeXp6avLkyS69Dz/99JMeffRRtWzZUn5+fqpdu7YGDhyotLQ0+zw//vijbDabXn311WL1W7dulc1m05IlS+zTjhw5ogceeEAhISHy8fFR27ZtNX/+fIe6LVu2yGazaenSpXruuefUoEED+fv7Kzs7u9ReX3nlFXXt2lW1a9eWn5+foqKi9P777zvMY7PZlJOTo3feecd++P3+++8vdZnl9fHVV1+pV69eCgoKkr+/v7p166YvvvjCYRlnzpzR+PHjFRERIR8fHwUHB6tHjx7auXOnfZ6SzrHLzMzU/fffr6CgINWoUUMjRoxQZmZmqb1erOiUg88++0yPPPKIateurcDAQMXHx+uXX35xmLesfTEzM1Pjx49XWFiYfHx81KxZM02dOpXRRVgeI3bANSYrK0snT550mGaz2VS7dm2HaQsWLNC5c+f08MMPy8fHR7Vq1bK/NnDgQDVv3lyTJk2SMUaS9NBDD+mdd97RH//4R/35z3/WV199pcmTJ2vv3r1auXKlw7L37dunIUOG6JFHHtGoUaPUsmXLMnv+5Zdf1KdPHw0aNEhDhgzRe++9pzFjxsjb21sPPPCAqlevrrvuukvLli3TjBkz5Onpaa9dsmSJjDEaNmyYS+/T119/ra1bt+ree+9Vw4YNlZaWptmzZ+u2227Td999J39/fzVp0kQ33XSTFi1apMcff9yhftGiRbruuuvUv39/SVJ6err+8Ic/yGazKSEhQXXr1tXatWv14IMPKjs7W+PHj3eonzhxory9vfXEE08oLy+vxNHSIn/729/Ur18/DRs2TPn5+Vq6dKkGDhyof/7zn+rbt68k6d1339VDDz2kzp076+GHH5YkNW3atNz3oaQ+PvnkE/Xu3VtRUVFKTk6Wh4eHFixYoO7du+vf//63OnfuLEkaPXq03n//fSUkJKhNmzY6deqUPv/8c+3du1cdO3YscX3GGPXv31+ff/65Ro8erdatW2vlypUaMWJEub1eLCEhQTVq1NCLL76offv2afbs2frpp5/sgbVISftibm6uunXrpiNHjuiRRx5Ro0aNtHXrViUlJenYsWOaOXOmS70A1xQD4JqwYMECI6nEh4+Pj32+Q4cOGUkmMDDQZGRkOCwjOTnZSDJDhgxxmJ6ammokmYceeshh+hNPPGEkmU8++cQ+LTw83Egy69atc6rvbt26GUlm+vTp9ml5eXnmhhtuMMHBwSY/P98YY8z69euNJLN27VqH+uuvv95069at3PVIMsnJyfbnubm5xeZJSUkxkszf//53+7Q333zTSDJ79+61T8vPzzd16tQxI0aMsE978MEHTf369c3JkycdlnnvvfeaoKAg+/o2b95sJJkmTZqU2ENJLp0vPz/ftGvXznTv3t1hekBAgENPZSmtj8LCQtO8eXPTs2dPU1hY6NBD48aNTY8ePezTgoKCzNixY8tcz4gRI0x4eLj9+apVq4wk8/LLL9unXbhwwdxyyy1GklmwYEGZyyvaz6Oiouz7hjHGvPzyy0aS+fDDD+3TStsXJ06caAICAsz+/fsdpk+YMMF4enqaw4cPl9kDcC3jUCxwjZk1a5Y2bNjg8Fi7dm2x+e655x7VrVu3xGWMHj3a4fnHH38sSUpMTHSY/uc//1mStGbNGofpjRs3Vs+ePZ3uuVq1anrkkUfsz729vfXII48oIyNDO3bskCTFxMQoNDRUixYtss+3Z88e7d69W/fdd5/T6ypy8XlW58+f16lTp9SsWTPVqFHD4VDioEGD5Ovr67De9evX6+TJk/b1GmP0wQcfKC4uTsYYnTx50v7o2bOnsrKyHJYpSSNGjHD6XK+L5/vll1+UlZWlW265pdgyK+LSPlJTU3XgwAENHTpUp06dsm9HTk6O7rjjDn322Wf2w5U1atTQV199paNHjzq9vo8//ljVqlXTmDFj7NM8PT312GOPudT3ww8/7HD+3pgxY1StWjX7vlqkpH1x+fLluuWWW1SzZk2Hn1VMTIwKCgr02WefudQLcC3hUCxwjencubNTF0+UdOVsaa/99NNP8vDwKHZlbb169VSjRg399NNPTi+7JKGhocUu0GjRooWk384J/MMf/iAPDw8NGzZMs2fPVm5urvz9/bVo0SL5+vpq4MCBLq1Pkn799VdNnjxZCxYs0JEjR+yHnKXfDmcXqVGjhuLi4rR48WJNnDhR0m+HYRs0aKDu3btLkk6cOKHMzEzNnTtXc+fOLXF9GRkZDs9deY/++c9/6n/+53+UmprqcE7jxYccK+rSPg4cOCBJZR4azcrKUs2aNfXyyy9rxIgRCgsLU1RUlPr06aP4+Hg1adKk1NqffvpJ9evXV/Xq1R2ml3e4/lLNmzd3eF69enXVr1/f4RxJqeT3+cCBA9q9e3epf9hc+rMCrIRgB1hUWaNFpb3mbJC4WlcdxsfHa9q0aVq1apWGDBmixYsX684771RQUJDLy3rssce0YMECjR8/XtHR0QoKCpLNZtO9995b7AT6+Ph4LV++XFu3blX79u21evVqPfroo/arR4vmv++++0oNRNdff73Dc2ffo3//+9/q16+fbr31Vr3xxhuqX7++vLy8tGDBAi1evNjVzS7m0j6KtmXatGm64YYbSqwpCmWDBg3SLbfcopUrV+pf//qXpk2bpqlTp2rFihXq3bv3Zfd2JZT0PhcWFqpHjx566qmnSqwp+qMCsCKCHQCFh4ersLBQBw4cUOvWre3T09PTlZmZqfDw8Mta/tGjR4vdVmX//v2S5HBFZbt27dShQwctWrRIDRs21OHDh/Xaa69VaJ3vv/++RowYoenTp9unnTt3rsSrM3v16qW6detq0aJF6tKli3JzczV8+HD763Xr1tV1112ngoICxcTEVKif0nzwwQfy9fXV+vXr5ePjY5++YMGCYvNeiRG8ogsuAgMDndqW+vXr69FHH9Wjjz6qjIwMdezYUX/9619LDXbh4eHatGmTzp496zBqt2/fPpf6PHDggG6//Xb787Nnz+rYsWPq06dPubVNmzbV2bNnr/jPCrgWcI4dAPsvy0uvFpwxY4Yk2a/MrKgLFy443BIlPz9fb775purWrauoqCiHeYcPH65//etfmjlzpmrXrl3hkSFPT0+Hw6+S9Nprr6mgoKDYvNWqVbNfrbtw4UK1b9/eYQTO09NT99xzjz744APt2bOnWP2JEycq1GPRsm02m0NfaWlpJX7DREBAgNO3DSlNVFSUmjZtqldeeUVnz54t9nrRthQUFDgcspak4OBghYaGFrsFzsX69OmjCxcuaPbs2fZpBQUFLgf0uXPn6vz58/bns2fP1oULF5zaHwYNGqSUlBStX7++2GuZmZm6cOGCS70A1xJG7IBrzNq1a/X9998Xm961a9cyz30qS2RkpEaMGKG5c+cqMzNT3bp107Zt2/TOO+9owIABDiMnFREaGqqpU6cqLS1NLVq00LJly5Samqq5c+cWu8Ht0KFD9dRTT2nlypUaM2ZMhW+Ae+edd+rdd99VUFCQ2rRpo5SUFG3cuLHYbWGKxMfH63//93+1efNmTZ06tdjrU6ZM0ebNm9WlSxeNGjVKbdq00enTp7Vz505t3LhRp0+frlCfffv21YwZM9SrVy8NHTpUGRkZmjVrlpo1a6bdu3c7zBsVFaWNGzdqxowZCg0NVePGjdWlSxeX1ufh4aG33npLvXv3Vtu2bTVy5Eg1aNBAR44c0ebNmxUYGKiPPvpIZ86cUcOGDfXHP/5RkZGRql69ujZu3Kivv/7aYRT0UnFxcbrppps0YcIEpaWlqU2bNlqxYkWxkFie/Px83XHHHRo0aJD27dunN954QzfffLP69etXbu2TTz6p1atX684779T999+vqKgo5eTk6Ntvv9X777+vtLQ01alTx6V+gGuGey/KBeCssm53ootuI1F0u5Np06YVW0bR7U5OnDhR7LXz58+bl156yTRu3Nh4eXmZsLAwk5SUZM6dO+cwX3h4uOnbt6/TfXfr1s20bdvWbN++3URHRxtfX18THh5uXn/99VJr+vTpYySZrVu3Or0eXXK7k19++cWMHDnS1KlTx1SvXt307NnTfP/99yY8PLzUW4a0bdvWeHh4mP/+978lvp6enm7Gjh1rwsLCjJeXl6lXr5654447zNy5c+3zFN1mZPny5U73/vbbb5vmzZsbHx8f06pVK7NgwQL7z+pi33//vbn11luNn5+fkVTmrU/K62PXrl3m7rvvNrVr1zY+Pj4mPDzcDBo0yGzatMkY89staZ588kkTGRlprrvuOhMQEGAiIyPNG2+84bCcS293Yowxp06dMsOHDzeBgYEmKCjIDB8+3Ozatcul2518+umn5uGHHzY1a9Y01atXN8OGDTOnTp1ymLesffHMmTMmKSnJNGvWzHh7e5s6deqYrl27mldeecXhNiqA1diMueRYBQC42V133aVvv/1WBw8erNT1dujQQbVq1dKmTZsqdb34PwsXLtTIkSP19ddfu/zVeQA4xw5AFXPs2DGtWbPG4eKFyrB9+3alpqYqPj6+UtcLAFcS59gBqBIOHTqkL774Qm+99Za8vLwcbmh8Ne3Zs0c7duzQ9OnTVb9+fQ0ePLhS1gsAVwMjdgCqhE8//VTDhw/XoUOH9M4776hevXqVst73339fI0eO1Pnz57VkyRL5+vpWynoB4GrgHDsAAACLYMQOAADAIgh2AAAAFvG7u3iisLBQR48e1XXXXXdFvp4HAADgajLG6MyZMwoNDbV/h3VpfnfB7ujRowoLC3N3GwAAAC75+eef1bBhwzLn+d0Fu+uuu07Sb29OYGCgm7sBAAAoW3Z2tsLCwuwZpiy/u2BXdPg1MDCQYAcAAK4ZzpxCxsUTAAAAFkGwAwAAsAiCHQAAgEX87s6xc1ZBQYHOnz/v7jYsx8vLS56enu5uAwAASyLYXcIYo+PHjyszM9PdrVhWjRo1VK9ePe4jCADAFUawu0RRqAsODpa/vz/h4woyxig3N1cZGRmSpPr167u5IwAArIVgd5GCggJ7qKtdu7a727EkPz8/SVJGRoaCg4M5LAsAwBXExRMXKTqnzt/f382dWFvR+8s5jAAAXFkEuxJw+PXq4v0FAODqINgBAABYBMEOAADAIrh4wkkRE9ZU6vrSpvSt1PUBAIBrn1tH7D777DPFxcUpNDRUNptNq1atKnP+FStWqEePHqpbt64CAwMVHR2t9evXV06zAAAAVZxbg11OTo4iIyM1a9Ysp+b/7LPP1KNHD3388cfasWOHbr/9dsXFxWnXrl1XudOq77bbbtNjjz2m8ePHq2bNmgoJCdG8efOUk5OjkSNH6rrrrlOzZs20du1ae82ePXvUu3dvVa9eXSEhIRo+fLhOnjxpf33dunW6+eabVaNGDdWuXVt33nmnfvjhB/vraWlpstlsWrFihW6//Xb5+/srMjJSKSkplbrtAADgN24Ndr1799b//M//6K677nJq/pkzZ+qpp57SjTfeqObNm2vSpElq3ry5Pvroo6vc6bXhnXfeUZ06dbRt2zY99thjGjNmjAYOHKiuXbtq586dio2N1fDhw5Wbm6vMzEx1795dHTp00Pbt27Vu3Tqlp6dr0KBB9uXl5OQoMTFR27dv16ZNm+Th4aG77rpLhYWFDut99tln9cQTTyg1NVUtWrTQkCFDdOHChcrefAAAfveu6XPsCgsLdebMGdWqVcvdrVQJkZGReu655yRJSUlJmjJliurUqaNRo0ZJkl544QXNnj1bu3fv1saNG9WhQwdNmjTJXj9//nyFhYVp//79atGihe655x6H5c+fP19169bVd999p3bt2tmnP/HEE+rb97dzAl966SW1bdtWBw8eVKtWra72JgMAgItc01fFvvLKKzp79qzDKNOl8vLylJ2d7fCwquuvv97+b09PT9WuXVvt27e3TwsJCZH027c+fPPNN9q8ebOqV69ufxQFsaLDrQcOHNCQIUPUpEkTBQYGKiIiQpJ0+PDhUtdb9DVhRV8bBgAAKs81O2K3ePFivfTSS/rwww8VHBxc6nyTJ0/WSy+9VImduY+Xl5fDc5vN5jCt6MbAhYWFOnv2rOLi4jR16tRiyykKZ3FxcQoPD9e8efMUGhqqwsJCtWvXTvn5+aWu9+J1AABgRZfeKaMq3cnimgx2S5cu1UMPPaTly5crJiamzHmTkpKUmJhof56dna2wsLCr3WKV17FjR33wwQeKiIhQtWrFd4NTp05p3759mjdvnm655RZJ0ueff17ZbQIAABdcc4dilyxZopEjR2rJkiX287rK4uPjo8DAQIcHpLFjx+r06dMaMmSIvv76a/3www9av369Ro4cqYKCAtWsWVO1a9fW3LlzdfDgQX3yyScOARkAAFQ9bg12Z8+eVWpqqlJTUyVJhw4dUmpqqv0crqSkJMXHx9vnX7x4seLj4zV9+nR16dJFx48f1/Hjx5WVleWO9q9poaGh+uKLL1RQUKDY2Fi1b99e48ePV40aNeTh4SEPDw8tXbpUO3bsULt27fT4449r2rRp7m4bAACUwWaMMe5a+ZYtW3T77bcXmz5ixAgtXLhQ999/v9LS0rRlyxZJv92r7dNPPy11fmdkZ2crKChIWVlZxUbvzp07p0OHDqlx48by9fV1eXvgHN5nAMC1rLLPsSsru1zKrefY3XbbbSorV14a1ooCHgAAAIq75s6xAwAAQMkIdgAAABZBsAMAALAIgh0AAIBFEOxKwLcmXF28vwAAXB3X5DdPXC3e3t7y8PDQ0aNHVbduXXl7e9u/IguXzxij/Px8nThxQh4eHvL29nZ3SwAAWArB7iIeHh5q3Lixjh07pqNHj7q7Hcvy9/dXo0aN5OHBgDEAAFcSwe4S3t7eatSokS5cuKCCggJ3t2M5np6eqlatGiOhAABcBQS7EthsNnl5ecnLy8vdrQAAADiNY2EAAAAWQbADAACwCIIdAACARRDsAAAALIJgBwAAYBEEOwAAAIsg2AEAAFgEwQ4AAMAiCHYAAAAWQbADAACwCIIdAACARRDsAAAALIJgBwAAYBEEOwAAAIsg2AEAAFgEwQ4AAMAiCHYAAAAWQbADAACwCIIdAACARRDsAAAALIJgBwAAYBEEOwAAAIsg2AEAAFgEwQ4AAMAiCHYAAAAWQbADAACwCIIdAACARRDsAAAALIJgBwAAYBEEOwAAAIsg2AEAAFgEwQ4AAMAiCHYAAAAWQbADAACwCIIdAACARRDsAAAALIJgBwAAYBEEOwAAAIsg2AEAAFgEwQ4AAMAiCHYAAAAWQbADAACwCIIdAACARRDsAAAALMKtwe6zzz5TXFycQkNDZbPZtGrVqnJrtmzZoo4dO8rHx0fNmjXTwoULr3qfAAAA1wK3BrucnBxFRkZq1qxZTs1/6NAh9e3bV7fffrtSU1M1fvx4PfTQQ1q/fv1V7hQAAKDqq+bOlffu3Vu9e/d2ev45c+aocePGmj59uiSpdevW+vzzz/Xqq6+qZ8+eV6tNAACAa8I1dY5dSkqKYmJiHKb17NlTKSkpbuoIAACg6nDriJ2rjh8/rpCQEIdpISEhys7O1q+//io/P79iNXl5ecrLy7M/z87Ovup9AgAAuMM1NWJXEZMnT1ZQUJD9ERYW5u6WAAAAroprKtjVq1dP6enpDtPS09MVGBhY4midJCUlJSkrK8v++PnnnyujVQAAgEp3TR2KjY6O1scff+wwbcOGDYqOji61xsfHRz4+Ple7NQAAALdz64jd2bNnlZqaqtTUVEm/3c4kNTVVhw8flvTbaFt8fLx9/tGjR+vHH3/UU089pe+//15vvPGG3nvvPT3++OPuaB8AAKBKcWuw2759uzp06KAOHTpIkhITE9WhQwe98MILkqRjx47ZQ54kNW7cWGvWrNGGDRsUGRmp6dOn66233uJWJwAAAJJsxhjj7iYqU3Z2toKCgpSVlaXAwEB3twMAAK4xERPWODxPm9L3qq7PlexyTV08AQAAgNIR7AAAACyCYAcAAGARBDsAAACLINgBAABYBMEOAADAIgh2AAAAFkGwAwAAsAiCHQAAgEUQ7AAAACyCYAcAAGARBDsAAACLINgBAABYBMEOAADAIgh2AAAAFkGwAwAAsAiCHQAAgEUQ7AAAACyCYAcAAGARBDsAAACLINgBAABYBMEOAADAIqq5uwEAAIDKFDFhjf3faVP6urGTK48ROwAAAIsg2AEAAFgEwQ4AAMAiCHYAAAAWQbADAACwCIIdAACARRDsAAAALIL72AEAgGuKle9Dd7kYsQMAALAIgh0AAIBFEOwAAAAsgmAHAABgEQQ7AAAAiyDYAQAAWATBDgAAwCIIdgAAABZBsAMAALAIgh0AAIBFEOwAAAAsgmAHAABgEQQ7AAAAiyDYAQAAWATBDgAAwCIIdgAAABZRzd0NAACA35eICWvs/06b0teNnVgPI3YAAAAWQbADAACwCIIdAACARRDsAAAALIJgBwAAYBFuD3azZs1SRESEfH191aVLF23btq3M+WfOnKmWLVvKz89PYWFhevzxx3Xu3LlK6hYAAKDqcmuwW7ZsmRITE5WcnKydO3cqMjJSPXv2VEZGRonzL168WBMmTFBycrL27t2rt99+W8uWLdMzzzxTyZ0DAABUPW4NdjNmzNCoUaM0cuRItWnTRnPmzJG/v7/mz59f4vxbt27VTTfdpKFDhyoiIkKxsbEaMmRIuaN8AAAAvwduC3b5+fnasWOHYmJi/q8ZDw/FxMQoJSWlxJquXbtqx44d9iD3448/6uOPP1afPn0qpWcAAICqzG3fPHHy5EkVFBQoJCTEYXpISIi+//77EmuGDh2qkydP6uabb5YxRhcuXNDo0aPLPBSbl5envLw8+/Ps7OwrswEAAABVjNsvnnDFli1bNGnSJL3xxhvauXOnVqxYoTVr1mjixIml1kyePFlBQUH2R1hYWCV2DAAAUHncNmJXp04deXp6Kj093WF6enq66tWrV2LN888/r+HDh+uhhx6SJLVv3145OTl6+OGH9eyzz8rDo3hOTUpKUmJiov15dnY24Q4AAFiS20bsvL29FRUVpU2bNtmnFRYWatOmTYqOji6xJjc3t1h48/T0lCQZY0qs8fHxUWBgoMMDAADAitw2YidJiYmJGjFihDp16qTOnTtr5syZysnJ0ciRIyVJ8fHxatCggSZPnixJiouL04wZM9ShQwd16dJFBw8e1PPPP6+4uDh7wAMAAFdPxIQ19n+nTenrxk5QErcGu8GDB+vEiRN64YUXdPz4cd1www1at26d/YKKw4cPO4zQPffcc7LZbHruued05MgR1a1bV3FxcfrrX//qrk0AAACoMtwa7CQpISFBCQkJJb62ZcsWh+fVqlVTcnKykpOTK6EzAACAa8s1dVUsAAAASkewAwAAsAiCHQAAgEUQ7AAAACyCYAcAAGARBDsAAACLINgBAABYBMEOAADAIgh2AAAAFkGwAwAAsAiCHQAAgEUQ7AAAACyimrsbAAAAlSdiwhr7v9Om9HVjJ7gaGLEDAACwCIIdAACARRDsAAAALIJgBwAAYBEEOwAAAIsg2AEAAFgEwQ4AAMAiCHYAAAAWQbADAACwCIIdAACARRDsAAAALIJgBwAAYBHV3N0AAABwXsSENfZ/p03p68ZOUBUxYgcAAGARBDsAAACLINgBAABYBMEOAADAIgh2AAAAFkGwAwAAsAiCHQAAgEVwHzsAACrJxfegk7gPHa48l0fszp8/r2rVqmnPnj1Xox8AAABUkMvBzsvLS40aNVJBQcHV6AcAAAAVVKFz7J599lk988wzOn369JXuBwAAABVUoXPsXn/9dR08eFChoaEKDw9XQECAw+s7d+68Is0BAADAeRUKdgMGDLjCbQAAAOByVSjYJScnX+k+AAAAcJku63YnO3bs0N69eyVJbdu2VYcOHa5IUwAAAHBdhYJdRkaG7r33Xm3ZskU1atSQJGVmZur222/X0qVLVbdu3SvZIwAAAJxQoatiH3vsMZ05c0b/+c9/dPr0aZ0+fVp79uxRdna2/vSnP13pHgEAAOCECo3YrVu3Ths3blTr1q3t09q0aaNZs2YpNjb2ijUHAAAA51Uo2BUWFsrLy6vYdC8vLxUWFl52UwAAVEUXfyUYXweGqqhCh2K7d++ucePG6ejRo/ZpR44c0eOPP6477rjjijUHAAAA51Uo2L3++uvKzs5WRESEmjZtqqZNm6px48bKzs7Wa6+9dqV7BAAAgBMqdCg2LCxMO3fu1MaNG/X9999Lklq3bq2YmJgr2hwAAACc53KwO3/+vPz8/JSamqoePXqoR48eV6MvAAAAuMjlQ7FeXl5q1KiRCgoKrkY/AAAAqKAKnWP37LPP6plnntHp06evdD8AAFw1ERPW2B+AFVXoHLvXX39dBw8eVGhoqMLDwxUQEODw+s6dO69IcwAAAHBehYLdgAEDrnAbAAAAuFwuB7sLFy7IZrPpgQceUMOGDS+7gVmzZmnatGk6fvy4IiMj9dprr6lz586lzp+Zmalnn31WK1as0OnTpxUeHq6ZM2eqT58+l90LAADAtczlc+yqVaumadOm6cKFC5e98mXLlikxMVHJycnauXOnIiMj1bNnT2VkZJQ4f35+vnr06KG0tDS9//772rdvn+bNm6cGDRpcdi8AAADXugodiu3evbs+/fRTRUREXNbKZ8yYoVGjRmnkyJGSpDlz5mjNmjWaP3++JkyYUGz++fPn6/Tp09q6dav9K80utwcAAACrqFCw6927tyZMmKBvv/1WUVFRxS6e6NevX7nLyM/P144dO5SUlGSf5uHhoZiYGKWkpJRYs3r1akVHR2vs2LH68MMPVbduXQ0dOlRPP/20PD09K7IpAAAAllGhYPfoo49K+m3E7VI2m82pe9ydPHlSBQUFCgkJcZgeEhJi/zaLS/3444/65JNPNGzYMH388cc6ePCgHn30UZ0/f17Jyckl1uTl5SkvL8/+PDs7u9zeAAAArkUVCnaFhYVXug+n1xscHKy5c+fK09NTUVFROnLkiKZNm1ZqsJs8ebJeeumlSu4UAACg8rl08USfPn2UlZVlfz5lyhRlZmban586dUpt2rRxall16tSRp6en0tPTHaanp6erXr16JdbUr19fLVq0cDjs2rp1ax0/flz5+fkl1iQlJSkrK8v++Pnnn53qDwAA4FrjUrBbv369w2HNSZMmOXz7xIULF7Rv3z6nluXt7a2oqCht2rTJPq2wsFCbNm1SdHR0iTU33XSTDh486DBiuH//ftWvX1/e3t4l1vj4+CgwMNDhAQC4NvHNEUDZXAp2xpgyn7sqMTFR8+bN0zvvvKO9e/dqzJgxysnJsV8lGx8f73BxxZgxY3T69GmNGzdO+/fv15o1azRp0iSNHTv2svoAAACwggqdY3elDB48WCdOnNALL7yg48eP64YbbtC6devsF1QcPnxYHh7/lz3DwsK0fv16Pf7447r++uvVoEEDjRs3Tk8//bS7NgEAAKDKcCnY2Ww22Wy2YtMuR0JCghISEkp8bcuWLcWmRUdH68svv7ysdQIAAFiRS8HOGKP7779fPj4+kqRz585p9OjR9vvYXXz+HQAAACqXS8FuxIgRDs/vu+++YvPEx8dfXkcAAACoEJeC3YIFC65WHwAAALhMLl0VCwAAgKqLYAcAAGARBDsAAACLINgBAABYBMEOAADAItz6zRMAgN+PS7/fNW1KXzd1AlgXI3YAAAAWQbADAACwCIIdAACARRDsAAAALIJgBwAAYBEEOwAAAIsg2AEAAFgEwQ4AAMAiuEExAMApF99gmJsLA1UTI3YAAAAWQbADAACwCIIdAACARRDsAAAALIJgBwAAYBEEOwAAAIvgdicA8DvB7UoA62PEDgAAwCIIdgAAABZBsAMAALAIgh0AAIBFEOwAAAAsgmAHAABgEQQ7AAAAiyDYAQAAWATBDgAAwCL45gkAuAZc/K0REt8cAaBkjNgBAABYBMEOAADAIgh2AAAAFkGwAwAAsAiCHQAAgEUQ7AAAACyCYAcAAGARBDsAAACL4AbFAFAJLr7BMDcXBnC1MGIHAABgEQQ7AAAAiyDYAQAAWATn2AGAEzhHDsC1gBE7AAAAiyDYAQAAWATBDgAAwCIIdgAAABZBsAMAALAIgh0AAIBFVIlgN2vWLEVERMjX11ddunTRtm3bnKpbunSpbDabBgwYcHUbBAAAuAa4PdgtW7ZMiYmJSk5O1s6dOxUZGamePXsqIyOjzLq0tDQ98cQTuuWWWyqpUwAAgKrN7cFuxowZGjVqlEaOHKk2bdpozpw58vf31/z580utKSgo0LBhw/TSSy+pSZMmldgtAABA1eXWYJefn68dO3YoJibGPs3Dw0MxMTFKSUkpte4vf/mLgoOD9eCDD5a7jry8PGVnZzs8AAAArMitwe7kyZMqKChQSEiIw/SQkBAdP368xJrPP/9cb7/9tubNm+fUOiZPnqygoCD7Iyws7LL7BgAAqIrcfijWFWfOnNHw4cM1b9481alTx6mapKQkZWVl2R8///zzVe4SAADAPaq5c+V16tSRp6en0tPTHaanp6erXr16xeb/4YcflJaWpri4OPu0wsJCSVK1atW0b98+NW3a1KHGx8dHPj4+V6F7AACAqsWtwc7b21tRUVHatGmT/ZYlhYWF2rRpkxISEorN36pVK3377bcO05577jmdOXNGf/vb3zjMCqBUERPW2P+dNqWvGzsBgKvHrcFOkhITEzVixAh16tRJnTt31syZM5WTk6ORI0dKkuLj49WgQQNNnjxZvr6+ateunUN9jRo1JKnYdAAAgN8btwe7wYMH68SJE3rhhRd0/Phx3XDDDVq3bp39gorDhw/Lw+OaOhUQAADALdwe7CQpISGhxEOvkrRly5YyaxcuXHjlGwIAALgGMRQGAABgEQQ7AAAAiyDYAQAAWATBDgAAwCIIdgAAABZRJa6KBYCyXHxzYYkbDANAaRixAwAAsAiCHQAAgEUQ7AAAACyCYAcAAGARXDwB4Kq7+OIHLnwAgKuHETsAAACLINgBAABYBMEOAADAIjjHDkC5OEcOAK4NjNgBAABYBMEOAADAIgh2AAAAFsE5doDFXXx+nMQ5cgBgZYzYAQAAWATBDgAAwCIIdgAAABZBsAMAALAILp4AqjhuDgwAcBYjdgAAABZBsAMAALAIgh0AAIBFEOwAAAAsgosngKuMix8AAJWFETsAAACLINgBAABYBMEOAADAIgh2AAAAFsHFE0A5uPgBAHCtYMQOAADAIgh2AAAAFkGwAwAAsAiCHQAAgEVw8QQs7eILHyQufgAAWBsjdgAAABZBsAMAALAIgh0AAIBFcI4dqjRuDgwAgPMYsQMAALAIgh0AAIBFEOwAAAAsgnPscFVxjhwAAJWHETsAAACLINgBAABYBMEOAADAIgh2AAAAFkGwAwAAsAiCHQAAgEVUiWA3a9YsRUREyNfXV126dNG2bdtKnXfevHm65ZZbVLNmTdWsWVMxMTFlzg8AAPB74fZgt2zZMiUmJio5OVk7d+5UZGSkevbsqYyMjBLn37Jli4YMGaLNmzcrJSVFYWFhio2N1ZEjRyq5cwAAgKrF7cFuxowZGjVqlEaOHKk2bdpozpw58vf31/z580ucf9GiRXr00Ud1ww03qFWrVnrrrbdUWFioTZs2VXLnAAAAVYtbv3kiPz9fO3bsUFJSkn2ah4eHYmJilJKS4tQycnNzdf78edWqVavE1/Py8pSXl2d/np2dfXlN/87wzREAAFw73Dpid/LkSRUUFCgkJMRhekhIiI4fP+7UMp5++mmFhoYqJiamxNcnT56soKAg+yMsLOyy+wYAAKiK3H4o9nJMmTJFS5cu1cqVK+Xr61viPElJScrKyrI/fv7550ruEgAAoHK49VBsnTp15OnpqfT0dIfp6enpqlevXpm1r7zyiqZMmaKNGzfq+uuvL3U+Hx8f+fj4XJF+AQAAqjK3jth5e3srKirK4cKHogshoqOjS617+eWXNXHiRK1bt06dOnWqjFYBAACqPLeO2ElSYmKiRowYoU6dOqlz586aOXOmcnJyNHLkSElSfHy8GjRooMmTJ0uSpk6dqhdeeEGLFy9WRESE/Vy86tWrq3r16m7bjqqICx8AAPh9cXuwGzx4sE6cOKEXXnhBx48f1w033KB169bZL6g4fPiwPDz+b2Bx9uzZys/P1x//+EeH5SQnJ+vFF1+szNYBAACqFLcHO0lKSEhQQkJCia9t2bLF4XlaWtrVb6iKYMQNAAC44pq+KhYAAAD/h2AHAABgEQQ7AAAAiyDYAQAAWATBDgAAwCIIdgAAABZBsAMAALAIgh0AAIBFEOwAAAAsgmAHAABgEQQ7AAAAiyDYAQAAWATBDgAAwCIIdgAAABZBsAMAALAIgh0AAIBFEOwAAAAsgmAHAABgEQQ7AAAAiyDYAQAAWATBDgAAwCIIdgAAABZBsAMAALAIgh0AAIBFEOwAAAAsgmAHAABgEQQ7AAAAiyDYAQAAWATBDgAAwCIIdgAAABZBsAMAALAIgh0AAIBFEOwAAAAsgmAHAABgEQQ7AAAAiyDYAQAAWATBDgAAwCIIdgAAABZBsAMAALAIgh0AAIBFEOwAAAAsgmAHAABgEQQ7AAAAiyDYAQAAWATBDgAAwCIIdgAAABZBsAMAALCIau5uwMoiJqyx/zttSl83dgIAAH4PGLEDAACwCIIdAACARRDsAAAALIJgBwAAYBEEOwAAAIuoEsFu1qxZioiIkK+vr7p06aJt27aVOf/y5cvVqlUr+fr6qn379vr4448rqVMAAICqy+3BbtmyZUpMTFRycrJ27typyMhI9ezZUxkZGSXOv3XrVg0ZMkQPPvigdu3apQEDBmjAgAHas2dPJXcOAABQtbg92M2YMUOjRo3SyJEj1aZNG82ZM0f+/v6aP39+ifP/7W9/U69evfTkk0+qdevWmjhxojp27KjXX3+9kjsHAACoWtx6g+L8/Hzt2LFDSUlJ9mkeHh6KiYlRSkpKiTUpKSlKTEx0mNazZ0+tWrWqxPnz8vKUl5dnf56VlSVJys7Ovszuy1eYl2v/d0XW5+76qtDDlayvCj24u74q9MA28B5UlR7cXV8VeuB3i/t+jq4oWr4xpvyZjRsdOXLESDJbt251mP7kk0+azp07l1jj5eVlFi9e7DBt1qxZJjg4uMT5k5OTjSQePHjw4MGDB49r+vHzzz+Xm60s/5ViSUlJDiN8hYWFOn36tGrXri2bzVapvWRnZyssLEw///yzAgMDf3f1VaEHtoH34ErUV4Ue2Abeg6rSg7vrq0IPV2IbymKM0ZkzZxQaGlruvG4NdnXq1JGnp6fS09Mdpqenp6tevXol1tSrV8+l+X18fOTj4+MwrUaNGhVv+goIDAy8rB/8tV5fFXpgG3gPrkR9VeiBbeA9qCo9uLu+KvRwJbahNEFBQU7N59aLJ7y9vRUVFaVNmzbZpxUWFmrTpk2Kjo4usSY6OtphfknasGFDqfMDAAD8Xrj9UGxiYqJGjBihTp06qXPnzpo5c6ZycnI0cuRISVJ8fLwaNGigyZMnS5LGjRunbt26afr06erbt6+WLl2q7du3a+7cue7cDAAAALdze7AbPHiwTpw4oRdeeEHHjx/XDTfcoHXr1ikkJESSdPjwYXl4/N/AYteuXbV48WI999xzeuaZZ9S8eXOtWrVK7dq1c9cmOM3Hx0fJycnFDg3/XuqrQg9sA+/BlaivCj2wDbwHVaUHd9dXhR6uxDZcKTZjnLl2FgAAAFWd229QDAAAgCuDYAcAAGARBDsAAACLINgBAABYBMGuksyaNUsRERHy9fVVly5dtG3bNqdrP/vsM8XFxSk0NFQ2m63U78UtzeTJk3XjjTfquuuuU3BwsAYMGKB9+/Y5XT979mxdf/319hsvRkdHa+3atS71cLEpU6bIZrNp/PjxTte8+OKLstlsDo9WrVq5tN4jR47ovvvuU+3ateXn56f27dtr+/btTtVGREQUW7/NZtPYsWOdqi8oKNDzzz+vxo0by8/PT02bNtXEiROd+96/i5w5c0bjx49XeHi4/Pz81LVrV3399dclzlvefmOM0QsvvKD69evLz89PMTExOnDggNP1K1asUGxsrP1bXFJTU13q4fz583r66afVvn17BQQEKDQ0VPHx8Tp69KjTPbz44otq1aqVAgICVLNmTcXExOirr75yuv5io0ePls1m08yZM116H++///5i+0WvXr1c6mHv3r3q16+fgoKCFBAQoBtvvFGHDx92qr6k/dJms2natGlO1Z89e1YJCQlq2LCh/Pz81KZNG82ZM8el9yA9PV3333+/QkND5e/vr169etn3JWc+f86dO6exY8eqdu3aql69uu655x6HG9E7s4y5c+fqtttuU2BgoGw2mzIzM52uP336tB577DG1bNlSfn5+atSokf70pz/Zv1vcmfU/8sgjatq0qfz8/FS3bl31799f33//vUvbUMQYo969ezu8187U33bbbcX2g9GjR7u0/pSUFHXv3l0BAQEKDAzUrbfeql9//bXc+rS0tFL3xeXLlzvdw/HjxzV8+HDVq1dPAQEB6tixoz744AOn63/44Qfdddddqlu3rgIDAzVo0CD7vlTe77Ly9sPy6svaBysTwa4SLFu2TImJiUpOTtbOnTsVGRmpnj17KiMjw6n6nJwcRUZGatasWRVa/6effqqxY8fqyy+/1IYNG3T+/HnFxsYqJyfHqfqGDRtqypQp2rFjh7Zv367u3burf//++s9//uNyL19//bXefPNNXX/99S7Xtm3bVseOHbM/Pv/8c6drf/nlF910003y8vLS2rVr9d1332n69OmqWbOm031fvO4NGzZIkgYOHOhU/dSpUzV79my9/vrr2rt3r6ZOnaqXX35Zr732mtPbIEkPPfSQNmzYoHfffVfffvutYmNjFRMToyNHjhSbt7z95uWXX9b//u//as6cOfrqq68UEBCgnj176ty5c07V5+Tk6Oabb9bUqVNL7besZeTm5mrnzp16/vnntXPnTq1YsUL79u1Tv379nN6GFi1a6PXXX9e3336rzz//XBEREYqNjdWJEyecqi+ycuVKffnllyV+XY8zy+jVq5fD/rFkyRKn63/44QfdfPPNatWqlbZs2aLdu3fr+eefl6+vr1P1F6/32LFjmj9/vmw2m+655x6n6hMTE7Vu3Tr94x//0N69ezV+/HglJCRo9erVTm2DMUYDBgzQjz/+qA8//FC7du1SeHi4YmJilJOT49Tnz+OPP66PPvpIy5cv16effqqjR4/q7rvvtr/uzDJyc3PVq1cvPfPMM8V6LK/+6NGjOnr0qF555RXt2bNHCxcu1Lp16/Tggw86vf6oqCgtWLBAe/fu1fr162WMUWxsrAoKCpxeRpGZM2cW+8pLZ+tHjRrlsD+8/PLLTtenpKSoV69eio2N1bZt2/T1118rISFBHh4e5daHhYUV2xdfeuklVa9eXb1793a6h/j4eO3bt0+rV6/Wt99+q7vvvluDBg3Srl27yq3PyclRbGysbDabPvnkE33xxRfKz89XXFycCgsLy/1dVt5+WF59WftgpSr322Rx2Tp37mzGjh1rf15QUGBCQ0PN5MmTXV6WJLNy5crL6icjI8NIMp9++mmFl1GzZk3z1ltvuVRz5swZ07x5c7NhwwbTrVs3M27cOKdrk5OTTWRkpGtNXuTpp582N998c4XrLzVu3DjTtGlTU1hY6NT8ffv2NQ888IDDtLvvvtsMGzbM6XXm5uYaT09P889//tNheseOHc2zzz5bZu2l+01hYaGpV6+emTZtmn1aZmam8fHxMUuWLCm3/mKHDh0yksyuXbtc6qEk27ZtM5LMTz/9VKH6rKwsI8ls3LjR6fr//ve/pkGDBmbPnj0mPDzcvPrqqy5tw4gRI0z//v3L7Kus+sGDB5v77ruvwvWX6t+/v+nevbvT9W3btjV/+ctfHKaVtU9duox9+/YZSWbPnj32aQUFBaZu3bpm3rx5xeov/fzJzMw0Xl5eZvny5fZ59u7daySZlJSUEnso6zNs8+bNRpL55ZdfSqwtr77Ie++9Z7y9vc358+crVP/NN98YSebgwYMu9bBr1y7ToEEDc+zYsTJ/3iXVu/K5WlJ9ly5dzHPPPVfh+kvdcMMNxT73yltGQECA+fvf/+4wX61atZzal9avX288PDxMVlaWfZ7MzExjs9nMhg0bSuyh6HdZRfbDi+sv5sw+eDUxYneV5efna8eOHYqJibFP8/DwUExMjFJSUtzSU9HhhVq1arlcW1BQoKVLlyonJ8flr3EbO3as+vbt6/BeuOLAgQMKDQ1VkyZNNGzYMPuhKmesXr1anTp10sCBAxUcHKwOHTpo3rx5FeojPz9f//jHP/TAAw8U+6u6NF27dtWmTZu0f/9+SdI333yjzz//3P6XrDMuXLiggoIC+0hOET8/P5dGLyXp0KFDOn78uMPPIigoSF26dHHbfin9tm/abLYKfZ9zfn6+5s6dq6CgIEVGRjpVU1hYqOHDh+vJJ59U27ZtXV5nkS1btig4OFgtW7bUmDFjdOrUKafXv2bNGrVo0UI9e/ZUcHCwunTp4vLpFkXS09O1Zs0a+0iTM7p27arVq1fryJEjMsZo8+bN2r9/v2JjY52qz8vLkySH/dLDw0M+Pj4l7peXfv7s2LFD58+fd9gXW7VqpUaNGpW6L17OZ5iz9VlZWQoMDFS1asXv419efU5OjhYsWKDGjRsrLCzM6R5yc3M1dOhQzZo1q9TvPy+vh0WLFqlOnTpq166dkpKSlJub61R9RkaGvvrqKwUHB6tr164KCQlRt27dSv1sKe892LFjh1JTU8vcF0taRteuXbVs2TKdPn1ahYWFWrp0qc6dO6fbbrut3Pq8vDzZbDaHmwT7+vrKw8Oj2HZc+rvM1f3wcn4XXnVuiZO/I0eOHDGSzNatWx2mP/nkk6Zz584uL0+XOWJXUFBg+vbta2666SaX6nbv3m0CAgKMp6enCQoKMmvWrHGpfsmSJaZdu3bm119/Nca49pelMcZ8/PHH5r333jPffPONWbdunYmOjjaNGjUy2dnZTtX7+PgYHx8fk5SUZHbu3GnefPNN4+vraxYuXOjSdhhjzLJly4ynp6c5cuSI0zUFBQXm6aefNjabzVSrVs3YbDYzadIkl9cdHR1tunXrZo4cOWIuXLhg3n33XePh4WFatGhRZt2l+80XX3xhJJmjR486zDdw4EAzaNCgcusvdqVG7H799VfTsWNHM3ToUJfqP/roIxMQEGBsNpsJDQ0127Ztc7p+0qRJpkePHvaR14qM2C1ZssR8+OGHZvfu3WblypWmdevW5sYbbzQXLlwot75oVMbf39/MmDHD7Nq1y0yePNnYbDazZcsWp9+DIlOnTjU1a9a0/z9zpv7cuXMmPj7eSDLVqlUz3t7e5p133nH6PcjPzzeNGjUyAwcONKdPnzZ5eXlmypQpRpKJjY11qC3p82fRokXG29u72HpuvPFG89RTTxWbXt5nWHmjJc58Bp44ccI0atTIPPPMMy7Vz5o1ywQEBBhJpmXLlqWO1pW2jIcfftg8+OCD9uel/bxLq3/zzTfNunXrzO7du80//vEP06BBA3PXXXc5VZ+SkmIkmVq1apn58+ebnTt3mvHjxxtvb2+zf/9+p9+DImPGjDGtW7cu9fXSlvHLL7+Y2NhY+/4YGBho1q9f71R9RkaGCQwMNOPGjTM5OTnm7NmzJiEhwUgyDz/8sDGm9N9lzu6HzvwudPeIHcHuKqtqwW706NEmPDzc/Pzzzy7V5eXlmQMHDpjt27ebCRMmmDp16pj//Oc/TtUePnzYBAcHm2+++cY+zdVgd6lffvnFBAYGOn042MvLy0RHRztMe+yxx8wf/vAHl9cdGxtr7rzzTpdqlixZYho2bGiWLFlidu/ebf7+97+bWrVquRwsDx48aG699VYjyXh6epobb7zRDBs2zLRq1arMuqoe7PLz801cXJzp0KGDw2EUZ+rPnj1rDhw4YFJSUswDDzxgIiIiTHp6ern127dvNyEhIQ4BvSLB7lI//PCD04eDiz4fhgwZ4jBfXFycuffee11ef8uWLU1CQoJL/U+bNs20aNHCrF692nzzzTfmtddeM9WrVy/10FVJy9i+fbuJjIy075c9e/Y0vXv3Nr169XKYr6TPH1eDXXmfYeX9Ui2vPisry3Tu3Nn06tXL5Ofnu1SfmZlp9u/fbz799FMTFxdnOnbsWGLILmkZH374oWnWrJk5c+aMfVppP29nP8c3bdpU4uHgkuqLPhOSkpIc5m3fvr2ZMGGCS+vPzc01QUFB5pVXXim1t9KWkZCQYDp37mw2btxoUlNTzYsvvmiCgoLM7t27napfv369adKkibHZbMbT09Pcd999pmPHjmb06NHGmNJ/lzm7Hzrzu5BgZ3F5eXnG09Oz2H/O+Ph4069fP5eXdznBbuzYsaZhw4bmxx9/rFD9xe644w77X0DlWblypf0Dv+ghyf4fr6SRDWd06tSp2AdOaRo1auTwl7AxxrzxxhsmNDTUpXWmpaUZDw8Ps2rVKpfqGjZsaF5//XWHaRMnTjQtW7Z0aTlFzp49aw9lgwYNMn369Clz/kv3m6LwcWkYu/XWW82f/vSncusvdrnBLj8/3wwYMMBcf/315uTJky7XX6pZs2YljoZeWv/qq6/a98GL90sPDw8THh5+WT3UqVPHzJkzp9z6vLw8U61aNTNx4kSH+Z566inTtWtXl9b/2WefGUkmNTW11L4urc/NzTVeXl7Fztt88MEHTc+ePZ1axsUyMzNNRkaGMea3c4sfffRR+2ulff4UhY9Lfwk2atTIzJgxw2GaM59hZf1SLa8+OzvbREdHmzvuuKPEQObKZ2heXp7x9/c3ixcvdmoZ48aNK3V/7NatW4V6OHv2rJFk1q1bV279jz/+aCSZd99912H6oEGDHEbRnVn/3//+d+Pl5WXfFy5V2jIOHjxY7HxNY377ffPII4+41MOJEyfs+0BISIh5+eWXS5yv6HeZK/thSfUXc3ew4xy7q8zb21tRUVHatGmTfVphYaE2bdpUacfljTFKSEjQypUr9cknn6hx48aXvczCwkL7uTXlueOOO/Ttt98qNTXV/ujUqZOGDRum1NRUeXp6urz+s2fP6ocfflD9+vWdmv+mm24qdln8/v37FR4e7tJ6FyxYoODgYPXt29elutzcXHl4OP538/T0VGFhoUvLKRIQEKD69evrl19+0fr169W/f3+X6hs3bqx69eo57JfZ2dn66quvKvV8kfPnz2vQoEE6cOCANm7cqNq1a1/2Mp3dN4cPH67du3c77JehoaF68skntX79+gqv/7///a9OnTrl1L7p7e2tG2+88Yrsm2+//baioqKcPr9Q+u39P3/+/BXbN4OCglS3bl0dOHBA27dvV//+/cv9/ImKipKXl5fDvrhv3z4dPnzYvi9e7meYM/XZ2dmKjY2Vt7e3Vq9e7XDOYEXWb34bOLHvi+UtY8KECcX2R0l69dVXtWDBggr1ULSM+vXrl1sfERGh0NDQUvdFV9b/9ttvq1+/fqpbt26x96SsZRSdD1ja/uhKD3Xq1FGNGjX0ySefKCMjw+Fq+4sVfV44sx+WVV+luCVO/s4sXbrU+Pj4mIULF5rvvvvOPPzww6ZGjRrm+PHjTtWfOXPG7Nq1y+zatctIsp+LU9KVgyUZM2aMCQoKMlu2bDHHjh2zP3Jzc52qnzBhgvn000/NoUOHzO7du82ECROMzWYz//rXv5yqL4mrh2L//Oc/my1btphDhw6ZL774wsTExJg6deqU+hfhpbZt22aqVatm/vrXv5oDBw6YRYsWGX9/f/OPf/zD6R4KCgpMo0aNzNNPP+10TZERI0aYBg0amH/+85/m0KFDZsWKFaZOnTolHmoqy7p168zatWvNjz/+aP71r3+ZyMhI06VLlxIPGZW330yZMsXUqFHDfn5Y//79TePGje0jFeXVnzp1yuzatcusWbPGSDJLly41u3btMseOHXOqh/z8fNOvXz/TsGFDk5qa6rBv5uXllVt/9uxZk5SUZFJSUkxaWprZvn27GTlypPHx8bH/xe/q/52SDsWWtYwzZ86YJ554wqSkpJhDhw6ZjRs3mo4dO5rmzZubc+fOOdXDihUrjJeXl5k7d645cOCAee2114ynp6f597//7fQ2ZGVlGX9/fzN79myX94Nu3bqZtm3bms2bN5sff/zRLFiwwPj6+po33njD6WW89957ZvPmzeaHH34wq1atMuHh4ebuu+82xjj3+TN69GjTqFEj88knn5jt27eb6Ohoh1MnnFnGsWPHzK5du8y8efOMJPPZZ5+ZXbt2mVOnTpVbn5WVZbp06WLat29vDh486DDPhQsXyq3/4YcfzKRJk8z27dvNTz/9ZL744gsTFxdnatWqZT8toCKfw7podLS8+oMHD5q//OUvZvv27ebQoUPmww8/NE2aNDG33nqr0+t/9dVXTWBgoFm+fLk5cOCAee6554yvr685ePCg0/0fOHDA2Gw2s3bt2mLbU94y8vPzTbNmzcwtt9xivvrqK3Pw4EHzyiuvGJvNZtasWeNUD/PnzzcpKSnm4MGD5t133zW1atUyiYmJxpjyf5eVtx+WV1/WPliZCHaV5LXXXjONGjUy3t7epnPnzubLL790urZoWPfSx4gRI5yqL6lWklmwYIFT9Q888IAJDw833t7epm7duuaOO+64rFBnjOvBbvDgwaZ+/frG29vbNGjQwAwePLjUE5NL89FHH5l27doZHx8f06pVKzN37lyX6tevX28kmX379rlUZ8xvh3jGjRtnGjVqZHx9fU2TJk3Ms88+aw8wzlq2bJlp0qSJ8fb2NvXq1TNjx441mZmZJc5b3n5TWFhonn/+eRMSEmJ8fHzMHXfc4bBt5dUvWLCgxNeTk5OdWkbRIdySHps3by63/tdffzV33XWXCQ0NNd7e3qZ+/fqmX79+DhdPuPp/p6RgV9YycnNzTWxsrKlbt67x8vIy4eHhZtSoUQ5/tDnTw9tvv22aNWtmfH19TWRkpMOhfmfq33zzTePn51fivlBe/bFjx8z9999vQkNDja+vr2nZsqWZPn26w618ylvG3/72N9OwYUPj5eVlGjVqZJ577jn7vu3M58+vv/5qHn30UVOzZk3j7+9v7rrrLoc/EJxZRnJycqnzlFdf2vZJKnM/Lao/cuSI6d27twkODjZeXl6mYcOGZujQoeb77793aRsudXGwK6/+8OHD5tZbbzW1atUyPj4+plmzZubJJ5+0n7Pq7PonT55sGjZsaPz9/U10dLT9Dwxn65OSkkxYWJgpKCgocXvKW8b+/fvN3XffbYKDg42/v7+5/vrr7bc/cab+6aefNiEhIcbLy8s0b97cYV8u73dZefthefVl7YOVyWaMi7e+BwAAQJXEOXYAAAAWQbADAACwCIIdAACARRDsAAAALIJgBwAAYBEEOwAAAIsg2AEAAFgEwQ4AAMAiCHYAAAAWQbADAACwCIIdAACARRDsAAAALOL/AWuzz5SMugmQAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.arange(32)\n",
    "width = 0.2\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "rects1 = ax.bar(x - width, mean_diffs, width, label='mean')\n",
    "#rects2 = ax.bar(x, std_diffs, width, label='std')\n",
    "#rects3 = ax.bar(x + width, max_diffs, width, label='max')\n",
    "\n",
    "ax.set_ylabel('Error')\n",
    "ax.set_title('Error by layer at resid pre')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(x)\n",
    "ax.legend()\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HF activations tensor([ 1.8387e-03, -3.8147e-03,  9.6130e-04,  2.9297e-03, -3.9978e-03,\n",
      "        -8.0566e-03, -5.4016e-03, -2.9449e-03, -6.7444e-03, -3.8147e-06],\n",
      "       device='cuda:0')\n",
      "TL activations tensor([ 1.8387e-03, -3.8147e-03,  9.6130e-04,  2.9297e-03, -3.9978e-03,\n",
      "        -8.0566e-03, -5.4016e-03, -2.9449e-03, -6.7444e-03, -3.8147e-06],\n",
      "       device='cuda:1')\n",
      "Diff tensor([1.8387e-03, 3.8147e-03, 9.6130e-04, 2.9297e-03, 3.9978e-03, 8.0566e-03,\n",
      "        5.4016e-03, 2.9449e-03, 6.7444e-03, 3.8147e-06])\n",
      "Initial mean difference 0.003669357392936945\n",
      "Max difference 0.1337890625\n",
      "Max difference in last token position 0.10546875\n",
      "Mean difference in the last token position 0.007406735792756081\n",
      "Mean difference in first token position 0.00494754733517766\n"
     ]
    }
   ],
   "source": [
    "check_error_layer_resid_pre(0, atol=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HF activations tensor([ 0.0886, -0.5498,  0.3824, -0.1176, -0.3164,  0.5601,  0.5420,  0.2211,\n",
      "        -0.3377,  0.0552], device='cuda:0')\n",
      "TL activations tensor([ 0.0810, -0.5411,  0.3784, -0.1277, -0.3329,  0.5589,  0.5300,  0.2359,\n",
      "        -0.3244,  0.0455], device='cuda:1')\n",
      "Diff tensor([0.0886, 0.5498, 0.3824, 0.1176, 0.3164, 0.5601, 0.5420, 0.2211, 0.3377,\n",
      "        0.0552])\n",
      "Initial mean difference 0.31708166003227234\n",
      "Max difference 770.1580810546875\n",
      "Max difference in last token position 49.95972442626953\n",
      "Mean difference in the last token position 0.925025224685669\n",
      "Mean difference in first token position 0.6924221515655518\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/obalcells/a23-jailbreaks-obalcells/experiments/llama2_tl_bug/repro.ipynb Cell 20\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bprivsec0.inf.ethz.ch/home/obalcells/a23-jailbreaks-obalcells/experiments/llama2_tl_bug/repro.ipynb#X65sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m check_error_layer_resid_pre(\u001b[39m30\u001b[39;49m, atol\u001b[39m=\u001b[39;49m\u001b[39m0.2\u001b[39;49m)\n",
      "\u001b[1;32m/home/obalcells/a23-jailbreaks-obalcells/experiments/llama2_tl_bug/repro.ipynb Cell 20\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bprivsec0.inf.ethz.ch/home/obalcells/a23-jailbreaks-obalcells/experiments/llama2_tl_bug/repro.ipynb#X65sdnNjb2RlLXJlbW90ZQ%3D%3D?line=35'>36</a>\u001b[0m hf_wrapped_model\u001b[39m.\u001b[39mset_save_internal_decodings(\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bprivsec0.inf.ethz.ch/home/obalcells/a23-jailbreaks-obalcells/experiments/llama2_tl_bug/repro.ipynb#X65sdnNjb2RlLXJlbW90ZQ%3D%3D?line=36'>37</a>\u001b[0m hf_wrapped_model\u001b[39m.\u001b[39mreset_all()\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bprivsec0.inf.ethz.ch/home/obalcells/a23-jailbreaks-obalcells/experiments/llama2_tl_bug/repro.ipynb#X65sdnNjb2RlLXJlbW90ZQ%3D%3D?line=38'>39</a>\u001b[0m \u001b[39massert\u001b[39;00m torch\u001b[39m.\u001b[39mallclose(tl_activations_\u001b[39m.\u001b[39mcpu(), hf_activations\u001b[39m.\u001b[39mcpu(), atol\u001b[39m=\u001b[39matol)\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "check_error_layer_resid_pre(30, atol=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_relative_error_layer_resid_pre(layer, atol=1.0):\n",
    "    hf_wrapped_model.reset_all()\n",
    "    hf_wrapped_model.set_save_activations(True, layer)\n",
    "    hf_wrapped_model.set_save_internal_decodings(True)\n",
    "\n",
    "    tokens = tl_model.tokenizer.encode(\"Hello world! How are you?\", return_tensors=\"pt\").cpu()\n",
    "\n",
    "    hf_activations = torch.zeros((len(tokens), len(tokens[0]), 4096), device=\"cpu\", dtype=torch.float32)\n",
    "    tl_activations = torch.zeros_like(hf_activations, device=\"cpu\", dtype=torch.float32)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        hf_logits = hf_wrapped_model.get_logits(tokens.to(devices[0]))\n",
    "        hf_activations = hf_wrapped_model.get_last_activations(layer).cpu()\n",
    "        print(\"HF activations\", hf_activations[0, 0, :5])\n",
    "\n",
    "    def store_activations(activations, hook, tl_activations_):\n",
    "        tl_activations_ += activations.cpu()\n",
    "        print(\"TL activations\", tl_activations_[0, 0, :5])\n",
    "    \n",
    "    hook_filter = lambda name: name.startswith(f\"blocks.{layer}.hook_resid_pre\")\n",
    "    hook_fn = functools.partial(store_activations, tl_activations_=tl_activations)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        tl_model.run_with_hooks(\n",
    "            tokens.to(devices[1]),\n",
    "            prepend_bos=False,\n",
    "            fwd_hooks=[(hook_filter, hook_fn)],\n",
    "        )\n",
    "\n",
    "        \n",
    "    diff = torch.abs((hf_activations - tl_activations) / hf_activations)\n",
    "    print(\"Diff\", diff[0, 0, :5])\n",
    "\n",
    "    mean_diff = diff.mean().item()\n",
    "    std_diff = diff.std().item()\n",
    "    max_diff = diff.max().item()\n",
    "\n",
    "    print(f\"Layer {layer}, mean error: {mean_diff:.3f}, std diff: {std_diff:.3f}, max diff: {max_diff:.3f}\")\n",
    "\n",
    "    # print(\"Diff\", diff_[0,0,:10])\n",
    "    # print(\"Initial mean difference\", diff_[0,0,:10].mean().item())\n",
    "    # print(\"Max difference\", diff_.max().item())\n",
    "    # print(\"Max difference in last token position\", diff_[0,-1,:].max().item())\n",
    "    # print(\"Mean difference in the last token position\", diff_[-1,-1,:].mean().item())\n",
    "    # print(\"Mean difference in first token position\", diff_[-1,0,:].mean().item())\n",
    "\n",
    "    hf_wrapped_model.set_save_activations(False)\n",
    "    hf_wrapped_model.set_save_internal_decodings(False)\n",
    "    hf_wrapped_model.reset_all()\n",
    "\n",
    "    return mean_diff, std_diff, max_diff\n",
    "\n",
    "    # assert torch.allclose(tl_activations_.cpu(), hf_activations.cpu(), atol=atol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HF activations tensor([-0.0116,  0.0113,  0.0560,  0.0331, -0.1477])\n",
      "TL activations tensor([ 0.0018, -0.0038,  0.0010,  0.0029, -0.0040])\n",
      "Diff tensor([1.1582, 1.3382, 0.9828, 0.9115, 0.9729])\n",
      "Layer 0, mean error: 2.635, std diff: 87.518, max diff: 12687.897\n",
      "HF activations tensor([ 0.0699, -0.5114,  0.0642, -0.0617, -0.0583])\n",
      "TL activations tensor([-0.0130,  0.0088,  0.0571,  0.0356, -0.1513])\n",
      "Diff tensor([1.1862, 1.0171, 0.1104, 1.5774, 1.5940])\n",
      "Layer 1, mean error: 5.837, std diff: 520.253, max diff: 93607.367\n",
      "HF activations tensor([ 0.1070, -0.5451,  0.0946, -0.1130, -0.0241])\n",
      "TL activations tensor([ 0.0669, -0.5043,  0.0658, -0.0571, -0.0646])\n",
      "Diff tensor([0.3745, 0.0748, 0.3042, 0.4951, 1.6782])\n",
      "Layer 2, mean error: 3.360, std diff: 133.236, max diff: 22969.088\n",
      "HF activations tensor([ 0.1178, -0.5735,  0.1002, -0.1144, -0.0045])\n",
      "TL activations tensor([ 0.1041, -0.5380,  0.0961, -0.1084, -0.0304])\n",
      "Diff tensor([0.1162, 0.0620, 0.0404, 0.0526, 5.7385])\n",
      "Layer 3, mean error: 2.537, std diff: 41.379, max diff: 4148.770\n",
      "HF activations tensor([ 0.0043, -0.7096,  0.0107, -0.1676, -0.3199])\n",
      "TL activations tensor([ 0.1149, -0.5665,  0.1016, -0.1097, -0.0108])\n",
      "Diff tensor([25.4876,  0.2017,  8.5135,  0.3453,  0.9662])\n",
      "Layer 4, mean error: 2.935, std diff: 58.861, max diff: 8586.600\n",
      "HF activations tensor([ 0.0040, -0.6987,  0.0542, -0.1582, -0.3068])\n",
      "TL activations tensor([ 0.0020, -0.7024,  0.0125, -0.1630, -0.3252])\n",
      "Diff tensor([0.4909, 0.0054, 0.7689, 0.0300, 0.0599])\n",
      "Layer 5, mean error: 2.818, std diff: 63.920, max diff: 9381.199\n",
      "HF activations tensor([ 0.0092, -0.6800,  0.0698, -0.1853, -0.2771])\n",
      "TL activations tensor([ 0.0018, -0.6916,  0.0563, -0.1536, -0.3122])\n",
      "Diff tensor([0.8081, 0.0170, 0.1935, 0.1713, 0.1268])\n",
      "Layer 6, mean error: 2.820, std diff: 76.998, max diff: 12099.652\n",
      "HF activations tensor([ 0.0089, -0.6570,  0.0738, -0.2000, -0.2314])\n",
      "TL activations tensor([ 0.0070, -0.6727,  0.0718, -0.1807, -0.2824])\n",
      "Diff tensor([0.2080, 0.0238, 0.0277, 0.0965, 0.2206])\n",
      "Layer 7, mean error: 2.812, std diff: 41.815, max diff: 3584.681\n",
      "HF activations tensor([ 0.0204, -0.6517,  0.0920, -0.1836, -0.1794])\n",
      "TL activations tensor([ 0.0069, -0.6498,  0.0760, -0.1954, -0.2366])\n",
      "Diff tensor([0.6629, 0.0028, 0.1741, 0.0648, 0.3193])\n",
      "Layer 8, mean error: 3.072, std diff: 101.056, max diff: 15112.383\n",
      "HF activations tensor([ 0.0032, -0.5989,  0.0828, -0.1944, -0.1995])\n",
      "TL activations tensor([ 0.0184, -0.6442,  0.0942, -0.1792, -0.1844])\n",
      "Diff tensor([4.7890, 0.0756, 0.1376, 0.0783, 0.0753])\n",
      "Layer 9, mean error: 2.915, std diff: 68.289, max diff: 8867.148\n",
      "HF activations tensor([ 0.0416, -0.5579,  0.0965, -0.2527, -0.2029])\n",
      "TL activations tensor([ 0.0012, -0.5915,  0.0849, -0.1902, -0.2044])\n",
      "Diff tensor([0.9705, 0.0603, 0.1202, 0.2475, 0.0072])\n",
      "Layer 10, mean error: 3.313, std diff: 204.083, max diff: 36161.793\n",
      "HF activations tensor([ 0.0457, -0.5591,  0.1220, -0.2793, -0.2139])\n",
      "TL activations tensor([ 0.0396, -0.5505,  0.0985, -0.2486, -0.2080])\n",
      "Diff tensor([0.1337, 0.0154, 0.1928, 0.1099, 0.0279])\n",
      "Layer 11, mean error: 3.125, std diff: 86.829, max diff: 11877.921\n",
      "HF activations tensor([ 0.0473, -0.6102,  0.1359, -0.3197, -0.2041])\n",
      "TL activations tensor([ 0.0440, -0.5518,  0.1237, -0.2752, -0.2190])\n",
      "Diff tensor([0.0689, 0.0958, 0.0902, 0.1391, 0.0731])\n",
      "Layer 12, mean error: 6.703, std diff: 561.362, max diff: 78252.656\n",
      "HF activations tensor([ 0.0248, -0.6272,  0.1405, -0.3627, -0.1848])\n",
      "TL activations tensor([ 0.0456, -0.6027,  0.1377, -0.3155, -0.2096])\n",
      "Diff tensor([0.8407, 0.0390, 0.0205, 0.1301, 0.1342])\n",
      "Layer 13, mean error: 2.812, std diff: 84.303, max diff: 12321.832\n",
      "HF activations tensor([ 0.0088, -0.6497,  0.1688, -0.4312, -0.1759])\n",
      "TL activations tensor([ 0.0229, -0.6197,  0.1425, -0.3584, -0.1906])\n",
      "Diff tensor([1.6030, 0.0463, 0.1559, 0.1689, 0.0837])\n",
      "Layer 14, mean error: 3.141, std diff: 142.163, max diff: 23751.621\n",
      "HF activations tensor([-0.0406, -0.6230,  0.2021, -0.5495, -0.1917])\n",
      "TL activations tensor([ 0.0073, -0.6420,  0.1706, -0.4270, -0.1818])\n",
      "Diff tensor([1.1784, 0.0304, 0.1558, 0.2230, 0.0516])\n",
      "Layer 15, mean error: 2.600, std diff: 85.486, max diff: 14386.854\n",
      "HF activations tensor([-0.3077, -0.4716,  0.2225, -0.2083, -0.6240])\n",
      "TL activations tensor([-0.0419, -0.6155,  0.2040, -0.5449, -0.1978])\n",
      "Diff tensor([0.8637, 0.3052, 0.0830, 1.6161, 0.6831])\n",
      "Layer 16, mean error: 3.836, std diff: 164.583, max diff: 27455.951\n",
      "HF activations tensor([-0.2519, -0.4438,  0.2036, -0.3261, -0.6328])\n",
      "TL activations tensor([-0.3085, -0.4641,  0.2245, -0.2037, -0.6297])\n",
      "Diff tensor([0.2243, 0.0457, 0.1023, 0.3753, 0.0050])\n",
      "Layer 17, mean error: 1.957, std diff: 31.865, max diff: 3840.505\n",
      "HF activations tensor([-0.2812, -0.4344,  0.2283, -0.3701, -0.6681])\n",
      "TL activations tensor([-0.2522, -0.4362,  0.2055, -0.3219, -0.6387])\n",
      "Diff tensor([0.1033, 0.0040, 0.0997, 0.1304, 0.0441])\n",
      "Layer 18, mean error: 2.585, std diff: 145.872, max diff: 25899.727\n",
      "HF activations tensor([-0.3204, -0.3803,  0.2613, -0.0405, -0.6127])\n",
      "TL activations tensor([-0.2817, -0.4269,  0.2302, -0.3658, -0.6738])\n",
      "Diff tensor([0.1206, 0.1227, 0.1191, 8.0279, 0.0998])\n",
      "Layer 19, mean error: 42.198, std diff: 7251.024, max diff: 1312546.375\n",
      "HF activations tensor([-0.3674, -0.3489,  0.2550, -0.1055, -0.5996])\n",
      "TL activations tensor([-0.3203, -0.3730,  0.2624, -0.0371, -0.6185])\n",
      "Diff tensor([0.1281, 0.0691, 0.0290, 0.6484, 0.0315])\n",
      "Layer 20, mean error: 2.205, std diff: 110.169, max diff: 19140.598\n",
      "HF activations tensor([-0.3182, -0.3518,  0.2062, -0.1075, -0.6134])\n",
      "TL activations tensor([-0.3680, -0.3418,  0.2558, -0.1022, -0.6067])\n",
      "Diff tensor([0.1566, 0.0286, 0.2405, 0.0491, 0.0110])\n",
      "Layer 21, mean error: 2.059, std diff: 42.661, max diff: 4052.627\n",
      "HF activations tensor([-0.2659, -0.3472,  0.2334, -0.1473, -0.6120])\n",
      "TL activations tensor([-0.3190, -0.3448,  0.2070, -0.1033, -0.6197])\n",
      "Diff tensor([0.2000, 0.0070, 0.1128, 0.2985, 0.0126])\n",
      "Layer 22, mean error: 1.639, std diff: 45.704, max diff: 6696.587\n",
      "HF activations tensor([-0.2705, -0.2738,  0.2164, -0.1645, -0.6174])\n",
      "TL activations tensor([-0.2664, -0.3406,  0.2337, -0.1434, -0.6183])\n",
      "Diff tensor([0.0153, 0.2440, 0.0795, 0.1283, 0.0016])\n",
      "Layer 23, mean error: 2.071, std diff: 97.575, max diff: 16658.121\n",
      "HF activations tensor([-0.2157, -0.2935,  0.1859, -0.1708, -0.5971])\n",
      "TL activations tensor([-0.2708, -0.2663,  0.2170, -0.1605, -0.6234])\n",
      "Diff tensor([0.2556, 0.0927, 0.1671, 0.0608, 0.0439])\n",
      "Layer 24, mean error: 1.174, std diff: 10.231, max diff: 770.487\n",
      "HF activations tensor([-0.2247, -0.3196,  0.1882, -0.1874, -0.5352])\n",
      "TL activations tensor([-0.2166, -0.2861,  0.1867, -0.1664, -0.6038])\n",
      "Diff tensor([0.0360, 0.1051, 0.0084, 0.1123, 0.1282])\n",
      "Layer 25, mean error: 1.563, std diff: 45.307, max diff: 7504.847\n",
      "HF activations tensor([-0.2035, -0.3021,  0.2229, -0.2110, -0.5241])\n",
      "TL activations tensor([-0.2261, -0.3120,  0.1890, -0.1838, -0.5413])\n",
      "Diff tensor([0.1110, 0.0326, 0.1519, 0.1288, 0.0327])\n",
      "Layer 26, mean error: 1.510, std diff: 32.319, max diff: 4516.000\n",
      "HF activations tensor([-0.0803, -0.3972,  0.2596, -0.1679, -0.4328])\n",
      "TL activations tensor([-0.2050, -0.2943,  0.2242, -0.2069, -0.5308])\n",
      "Diff tensor([1.5516, 0.2592, 0.1362, 0.2328, 0.2263])\n",
      "Layer 27, mean error: 1.602, std diff: 30.027, max diff: 4107.910\n",
      "HF activations tensor([-0.0145, -0.5385,  0.2587, -0.2364, -0.4298])\n",
      "TL activations tensor([-0.0814, -0.3904,  0.2610, -0.1632, -0.4392])\n",
      "Diff tensor([4.6117, 0.2751, 0.0089, 0.3095, 0.0219])\n",
      "Layer 28, mean error: 2.079, std diff: 48.472, max diff: 5368.249\n",
      "HF activations tensor([ 0.0886, -0.5498,  0.3824, -0.1176, -0.3164])\n",
      "TL activations tensor([-0.0158, -0.5315,  0.2600, -0.2346, -0.4363])\n",
      "Diff tensor([1.1780, 0.0333, 0.3200, 0.9943, 0.3792])\n",
      "Layer 29, mean error: 1.882, std diff: 33.196, max diff: 3350.653\n",
      "HF activations tensor([-0.0069, -0.1699,  0.0211, -0.2171, -0.2469])\n",
      "TL activations tensor([ 0.0810, -0.5411,  0.3784, -0.1277, -0.3329])\n",
      "Diff tensor([12.7574,  2.1847, 16.9541,  0.4120,  0.3480])\n",
      "Layer 30, mean error: 2.769, std diff: 61.934, max diff: 9416.870\n",
      "HF activations tensor([ 0.4269, -0.1142,  0.0215,  0.0020, -0.3525])\n",
      "TL activations tensor([-0.0174, -0.1737,  0.0199, -0.2112, -0.2510])\n",
      "Diff tensor([1.0407e+00, 5.2118e-01, 7.0366e-02, 1.0766e+02, 2.8797e-01])\n",
      "Layer 31, mean error: 2.983, std diff: 31.037, max diff: 1977.813\n"
     ]
    }
   ],
   "source": [
    "mean_diffs = []\n",
    "std_diffs = []\n",
    "max_diffs = []\n",
    "\n",
    "for i in range(32):\n",
    "    mean_diff, std_diff, max_diff = check_relative_error_layer_resid_pre(i, atol=1.0)\n",
    "    mean_diffs.append(mean_diff)\n",
    "    std_diffs.append(std_diff)\n",
    "    max_diffs.append(max_diff)\n",
    "\n",
    "# plot the results using matplotlib in the same figure with legends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.arange(32)\n",
    "width = 0.2\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "rects1 = ax.bar(x - width, mean_diffs, width, label='mean')\n",
    "#rects2 = ax.bar(x, std_diffs, width, label='std')\n",
    "#rects3 = ax.bar(x + width, max_diffs, width, label='max')\n",
    "\n",
    "ax.set_ylabel('Error')\n",
    "ax.set_title('Error by layer at resid pre')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(x)\n",
    "ax.legend()\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "abs((hf_acts - tl_acts) / hf_acts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.arange(32)\n",
    "width = 0.2\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "rects1 = ax.bar(x - width, mean_diffs, width, label='mean')\n",
    "#rects2 = ax.bar(x, std_diffs, width, label='std')\n",
    "#rects3 = ax.bar(x + width, max_diffs, width, label='max')\n",
    "\n",
    "ax.set_ylabel('Error')\n",
    "ax.set_title('Error by layer at resid pre')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(x)\n",
    "ax.legend()\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is the layernorm at fault?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BlockOutputWrapper(torch.nn.Module):\n",
    "    def __init__(self, block, unembed_matrix, norm):\n",
    "        super().__init__()\n",
    "        self.block = block\n",
    "        self.unembed_matrix = unembed_matrix\n",
    "        self.norm = norm\n",
    "\n",
    "        self.block.self_attn = AttnWrapper(self.block.self_attn)\n",
    "        # self.input_layernorm = LlamaRMSNorm(config.hidden_size, eps=config.rms_norm_eps)\n",
    "        self.input_layernorm = self.block.input_layernorm\n",
    "        self.post_attention_layernorm = self.block.post_attention_layernorm\n",
    "\n",
    "        self.attn_out_unembedded = None\n",
    "        self.intermediate_resid_unembedded = None\n",
    "        self.mlp_out_unembedded = None\n",
    "        self.block_out_unembedded = None\n",
    "\n",
    "        self.activations = None\n",
    "\n",
    "        self.save_activations = False\n",
    "        self.save_internal_decodings = False\n",
    "\n",
    "    def forward(self, *args, **kwargs):\n",
    "        # print(kwargs.keys())\n",
    "        # print(args[0].shape)\n",
    "        if self.save_activations:\n",
    "            print(\"HF Pre activations\", args[0][0,0,:10])\n",
    "            self.activations = self.input_layernorm(args[0])\n",
    "        output = self.block(*args, **kwargs)\n",
    "        # activations: Float[Tensor, \"batch_size seq_len d_model\"] = output[0]\n",
    "        # if self.save_activations:\n",
    "        #     self.activations = activations\n",
    "        return output\n",
    "\n",
    "    def reset(self):\n",
    "        self.activations = None\n",
    "        self.block.self_attn.activations = None \n",
    "\n",
    "hf_wrapped_model.unwrap()\n",
    "hf_wrapped_model = Llama2Wrapper(hf_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ln1 = tl_model.blocks[0].ln1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_relative_error_layer_pre_attn(layer, atol=1.0):\n",
    "    hf_wrapped_model.reset_all()\n",
    "    hf_wrapped_model.set_save_activations(True, layer)\n",
    "    hf_wrapped_model.set_save_internal_decodings(True)\n",
    "\n",
    "    tokens = tl_model.tokenizer.encode(\"Hello world! How are you?\", return_tensors=\"pt\").cpu()\n",
    "\n",
    "    hf_activations = torch.zeros((len(tokens), len(tokens[0]), 4096), device=\"cpu\", dtype=torch.float32)\n",
    "    tl_activations = torch.zeros_like(hf_activations, device=\"cpu\", dtype=torch.float32)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        hf_logits = hf_wrapped_model.get_logits(tokens.to(devices[0]))\n",
    "        hf_activations = hf_wrapped_model.get_last_activations(layer).cpu()\n",
    "        print(\"HF activations\", hf_activations[0, 0, :5])\n",
    "\n",
    "    def store_activations(activations, hook, tl_activations_):\n",
    "        print(activations[0, 0, 0, :5])\n",
    "        tl_activations_ += ln1(activations[:,:,0,:]).cpu()\n",
    "        print(\"TL activations\", tl_activations_[0, 0, :5])\n",
    "    \n",
    "    # hook_filter = lambda name: name.startswith(f\"blocks.{layer}.hook_q_input\")\n",
    "    # tl_utils.get_act_name(layer, \"hook_q_input\")\n",
    "    # hook_name = tl_utils.get_act_name(\"q_input\", layer),\n",
    "    # print(hook_name)\n",
    "    hook_filter = lambda name: name.startswith(f\"blocks.{layer}.hook_attn_in\")\n",
    "    hook_fn = functools.partial(store_activations, tl_activations_=tl_activations)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        tl_model.run_with_hooks(\n",
    "            tokens.to(devices[1]),\n",
    "            prepend_bos=False,\n",
    "            fwd_hooks=[(hook_filter, hook_fn)],\n",
    "        )\n",
    "        \n",
    "    diff = torch.abs((hf_activations - tl_activations) / hf_activations)\n",
    "    print(\"Diff\", diff[0, 0, :5])\n",
    "\n",
    "    mean_diff = diff.mean().item()\n",
    "    std_diff = diff.std().item()\n",
    "    max_diff = diff.max().item()\n",
    "\n",
    "    print(f\"Layer {layer}, mean error: {mean_diff:.3f}, std diff: {std_diff:.3f}, max diff: {max_diff:.3f}\")\n",
    "\n",
    "    hf_wrapped_model.set_save_activations(False)\n",
    "    hf_wrapped_model.set_save_internal_decodings(False)\n",
    "    hf_wrapped_model.reset_all()\n",
    "\n",
    "    return mean_diff, std_diff, max_diff\n",
    "\n",
    "    # assert torch.allclose(tl_activations_.cpu(), hf_activations.cpu(), atol=atol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tl_model.set_use_hook_mlp_in(True)\n",
    "# tl_model.set_use_split_qkv_input(True)\n",
    "# tl_model.set_use_attn_result(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "tl_model.set_use_attn_in(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HF Pre activations tensor([ 1.8387e-03, -3.8147e-03,  9.6130e-04,  2.9297e-03, -3.9978e-03,\n",
      "        -8.0566e-03, -5.4016e-03, -2.9449e-03, -6.7444e-03, -3.8147e-06],\n",
      "       device='cuda:0')\n",
      "HF activations tensor([ 0.0065, -0.0064,  0.0004,  0.0046, -0.0072])\n",
      "tensor([ 0.0018, -0.0038,  0.0010,  0.0029, -0.0040], device='cuda:1')\n",
      "TL activations tensor([ 0.0070, -0.0068,  0.0004,  0.0049, -0.0077])\n",
      "Diff tensor([0.0710, 0.0710, 0.0710, 0.0710, 0.0710])\n",
      "Layer 0, mean error: 0.037, std diff: 0.016, max diff: 0.071\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.036657512187957764, 0.01582922227680683, 0.071043960750103)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_relative_error_layer_pre_attn(0, atol=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tl_model.tokenizer.encode(\"Hello world! How are you?\", return_tensors=\"pt\").cpu()\n",
    "hook_filter = utils.get_act_name\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    tl_model.run_with_hooks(\n",
    "        tokens.to(devices[1]),\n",
    "        prepend_bos=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replacing TL LN with HF LN at *every* layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in range(32):\n",
    "    tl_model.blocks[layer].ln1 = deepcopy(hf_wrapped_model.wrapped_model.model.layers[layer].block.input_layernorm).to(devices[1])\n",
    "    tl_model.blocks[layer].ln2 = deepcopy(hf_wrapped_model.wrapped_model.model.layers[layer].block.post_attention_layernorm).to(devices[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BlockOutputWrapper(torch.nn.Module):\n",
    "    def __init__(self, block, unembed_matrix, norm):\n",
    "        super().__init__()\n",
    "        self.block = block\n",
    "        self.unembed_matrix = unembed_matrix\n",
    "        self.norm = norm\n",
    "\n",
    "        self.block.self_attn = AttnWrapper(self.block.self_attn)\n",
    "        # self.input_layernorm = LlamaRMSNorm(config.hidden_size, eps=config.rms_norm_eps)\n",
    "        self.input_layernorm = self.block.input_layernorm\n",
    "        self.post_attention_layernorm = self.block.post_attention_layernorm\n",
    "\n",
    "        self.attn_out_unembedded = None\n",
    "        self.intermediate_resid_unembedded = None\n",
    "        self.mlp_out_unembedded = None\n",
    "        self.block_out_unembedded = None\n",
    "\n",
    "        self.activations = None\n",
    "\n",
    "        self.save_activations = False\n",
    "        self.save_internal_decodings = False\n",
    "\n",
    "    def forward(self, *args, **kwargs):\n",
    "        # print(kwargs.keys())\n",
    "        # print(args[0].shape)\n",
    "        # if self.save_activations:\n",
    "        #     print(\"HF Pre activations\", args[0][0,0,:10])\n",
    "        #     self.activations = self.input_layernorm(args[0])\n",
    "        output = self.block(*args, **kwargs)\n",
    "        # activations: Float[Tensor, \"batch_size seq_len d_model\"] = output[0]\n",
    "        # if self.save_activations:\n",
    "        #     self.activations = activations\n",
    "        return output\n",
    "\n",
    "    def reset(self):\n",
    "        self.activations = None\n",
    "        self.block.self_attn.activations = None \n",
    "\n",
    "# hf_wrapped_model.unwrap()\n",
    "hf_wrapped_model = Llama2Wrapper(hf_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in range(32):\n",
    "    hf_wrapped_model.wrapped_model.model.layers[layer].input_layernorm.to(devices[0])\n",
    "    post_attention_layernorm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "resid_pre_hook -> attn_in_hook -> ? -> attn_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_tl_rms(layer, disable_hooks=False, atol=1.0):\n",
    "    tokens = tl_model.tokenizer.encode(\"Hello world! How are you?\", return_tensors=\"pt\").cpu()\n",
    "\n",
    "    tl_activations = torch.zeros((len(tokens), len(tokens[0]), 4096), device=devices[1], dtype=torch.float32)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        hf_logits = hf_wrapped_model(tokens.to(devices[0])).logits\n",
    "\n",
    "    def calculate_attn(attn_in, hook, tl_activations_):\n",
    "        layer = hook.layer()\n",
    "        assert hook.name.endswith(\"hook_attn_in\"), \"Invalid attn hook\"\n",
    "        hf_ln = hf_wrapped_model.wrapped_model.model.layers[layer].input_layernorm.to(devices[1])\n",
    "        attn_out = tl_model.blocks[layer].attn(\n",
    "            query_input=hf_ln(attn_in),\n",
    "            key_input=hf_ln(attn_in),\n",
    "            value_input=hf_ln(attn_in),\n",
    "            past_kv_cache_entry=None,\n",
    "            attention_mask=None\n",
    "        )\n",
    "        hf_ln = hf_wrapped_model.wrapped_model.model.layers[layer].input_layernorm.to(devices[0])\n",
    "        if layer == 0:\n",
    "            print(attn_out.shape)\n",
    "        tl_activations_ += attn_out - tl_activations_\n",
    "\n",
    "    # elif hook.name.endswith(\"hook_mlp_in\"):\n",
    "    #     hf_ln = hf_wrapped_model.wrapped_model.model.layers[layer].post_attention_layernorm\n",
    "    #     tl_activations_ += hf_ln(activations) - tl_activations_\n",
    "\n",
    "    #     print(activations[0, 0, 0, :5])\n",
    "    #     tl_activations_ += ln1(activations[:,:,0,:]).cpu()\n",
    "    #     print(\"TL activations\", tl_activations_[0, 0, :5])\n",
    "    \n",
    "    # hook_filter = lambda name: name.startswith(f\"blocks.{layer}.hook_q_input\")\n",
    "    # tl_utils.get_act_name(layer, \"hook_q_input\")\n",
    "    # hook_name = tl_utils.get_act_name(\"q_input\", layer),\n",
    "    # print(hook_name)\n",
    "\n",
    "    hook_filter = lambda name: name.endswith(f\"hook_attn_in\")\n",
    "    hook_fn = functools.partial(\n",
    "        calculate_attn,\n",
    "        tl_activations_=tl_activations\n",
    "    )\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        tl_logits = tl_model.run_with_hooks(\n",
    "            tokens.to(devices[1]),\n",
    "            prepend_bos=False,\n",
    "            fwd_hooks=([] if disable_hooks else [(hook_filter, hook_fn)]),\n",
    "        )\n",
    "        \n",
    "    relative_error = torch.abs((hf_logits.cpu() - tl_logits.cpu()) / hf_logits.cpu())\n",
    "    print(\"Relative error\", relative_error[0, 0, :5])\n",
    "\n",
    "    mean_diff = relative_error.mean().item()\n",
    "    std_diff = relative_error.std().item()\n",
    "    max_diff = relative_error.max().item()\n",
    "\n",
    "    print(f\"Layer {layer}, mean rel. error: {mean_diff:.3f}, std diff: {std_diff:.3f}, max diff: {max_diff:.3f}\")\n",
    "\n",
    "    return mean_diff, std_diff, max_diff\n",
    "\n",
    "    # assert torch.allclose(tl_activations_.cpu(), hf_activations.cpu(), atol=atol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relative error tensor([0.1777, 0.8098, 0.0275, 0.0883, 0.0229])\n",
      "Layer 0, mean rel. error: 0.368, std diff: 12.150, max diff: 5055.095\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.3679742217063904, 12.150411605834961, 5055.0947265625)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# without replacement\n",
    "replace_tl_rms(0, atol=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relative error tensor([8.7756e-05, 1.5429e-03, 1.9755e-05, 1.9332e-05, 8.5034e-06])\n",
      "Layer 0, mean rel. error: 0.000, std diff: 0.001, max diff: 0.225\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1.5189039913821034e-05, 0.0005916812806390226, 0.22513586282730103)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# without replacement\n",
    "replace_tl_rms(0, disable_hooks=True, atol=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Llama2 RMSNorm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hf_ln_forward(self, hidden_states):\n",
    "    input_dtype = hidden_states.dtype\n",
    "    hidden_states = hidden_states.to(torch.float32)\n",
    "    variance = hidden_states.pow(2).mean(-1, keepdim=True)\n",
    "    hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
    "    return self.weight * hidden_states.to(input_dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TransformerLens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tl_ln_forward(\n",
    "    self, x: Float[torch.Tensor, \"batch pos length\"]\n",
    ") -> Float[torch.Tensor, \"batch pos length\"]:\n",
    "    if self.cfg.dtype not in [torch.float32, torch.float64]:\n",
    "        x = x.to(torch.float32)\n",
    "\n",
    "    scale: Float[torch.Tensor, \"batch pos 1\"] = self.hook_scale(\n",
    "        (x.pow(2).mean(-1, keepdim=True) + self.eps).sqrt()\n",
    "    )\n",
    "    x = self.hook_normalized(x * inv_scale).to(self.cfg.dtype)  # [batch, pos, length]\n",
    "    return x * self.w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixing the implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# self.wrapped_model.model.layers[i] = BlockOutputWrapper(\n",
    "#     layer, self.wrapped_model.lm_head, self.wrapped_model.model.norm\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RMSNorm(nn.Module):\n",
    "    def __init__(\n",
    "        self, cfg: Union[Dict, HookedTransformerConfig], length: Optional[int] = None\n",
    "    ):\n",
    "        \"\"\"\n",
    "        RMSNorm - LayerNorm without the centering and bias (RMS = Root Mean Square)\n",
    "\n",
    "        length (Optional[int]): If the dimension of the RMSNorm. If not provided, assumed to be d_model\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        if isinstance(cfg, Dict):\n",
    "            cfg = HookedTransformerConfig.from_dict(cfg)\n",
    "        self.cfg = cfg\n",
    "        self.eps = self.cfg.eps\n",
    "        if length is None:\n",
    "            self.length = self.cfg.d_model\n",
    "        else:\n",
    "            self.length = length\n",
    "\n",
    "        self.w = nn.Parameter(torch.ones(self.length, dtype=cfg.dtype))\n",
    "\n",
    "        # Adds a hook point for the normalisation scale factor\n",
    "        self.hook_scale = HookPoint()  # [batch, pos, 1]\n",
    "        self.hook_normalized = HookPoint()  # [batch, pos, length]\n",
    "\n",
    "    def forward(\n",
    "        self, x: Float[torch.Tensor, \"batch pos length\"]\n",
    "    ) -> Float[torch.Tensor, \"batch pos length\"]:\n",
    "        if self.cfg.dtype not in [torch.float32, torch.float64]:\n",
    "            x = x.to(torch.float32)\n",
    "\n",
    "        inv_scale = torch.rsqrt(x.pow(2).mean(-1, keepdim=True) + self.eps)\n",
    "\n",
    "        # scale: Float[torch.Tensor, \"batch pos 1\"] = self.hook_scale(\n",
    "        #     (x.pow(2).mean(-1, keepdim=True) + self.eps).sqrt()\n",
    "        # )\n",
    "        x = self.hook_normalized(x * inv_scale).to(self.cfg.dtype)  # [batch, pos, length]\n",
    "        return x * self.w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HF eps 1e-05\n",
      "HF w tensor([0.0298, 0.0140, 0.0031, 0.0131, 0.0151], device='cuda:1',\n",
      "       grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(f\"HF eps {tl_model.blocks[0].ln1.variance_epsilon}\")\n",
    "print(f\"HF w {tl_model.blocks[0].ln1.weight[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TL eps 1e-06\n",
      "TL w tensor([0.0298, 0.0140, 0.0031, 0.0131, 0.0151], device='cuda:1',\n",
      "       grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(f\"TL eps {tl_model.blocks[0].ln1.eps}\")\n",
    "print(f\"TL w {tl_model.blocks[0].ln1.w[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in range(32):\n",
    "    tl_model.blocks[layer].ln1 = deepcopy(hf_wrapped_model.wrapped_model.model.layers[layer].block.input_layernorm).to(devices[1])\n",
    "    tl_model.blocks[layer].ln2 = deepcopy(hf_wrapped_model.wrapped_model.model.layers[layer].block.post_attention_layernorm).to(devices[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tl_layer_norms = []\n",
    "for layer in range(32):\n",
    "    lns = [\n",
    "        deepcopy(tl_model.blocks[layer].ln1),\n",
    "        deepcopy(tl_model.blocks[layer].ln2)\n",
    "    ]\n",
    "    tl_layer_norms.append(lns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_norms = []\n",
    "for layer in range(32):\n",
    "    ln1 = RMSNorm(tl_model.cfg, length=tl_model.cfg.d_model)\n",
    "    ln2 = RMSNorm(tl_model.cfg, length=tl_model.cfg.d_model)\n",
    "    ln1.w = torch.nn.Parameter(hf_model.model.layers[layer].input_layernorm.weight.clone())\n",
    "    ln2.w = torch.nn.Parameter(hf_model.model.layers[layer].post_attention_layernorm.weight.clone())\n",
    "    ln1.to(devices[1])\n",
    "    ln2.to(devices[1])\n",
    "    lns = [ln1, ln2]\n",
    "    layer_norms.append(lns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Numerical error too large",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/obalcells/a23-jailbreaks-obalcells/experiments/llama2_tl_bug/repro.ipynb Cell 61\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bprivsec0.inf.ethz.ch/home/obalcells/a23-jailbreaks-obalcells/experiments/llama2_tl_bug/repro.ipynb#Y140sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# before changing ANYTHING\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bprivsec0.inf.ethz.ch/home/obalcells/a23-jailbreaks-obalcells/experiments/llama2_tl_bug/repro.ipynb#Y140sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bprivsec0.inf.ethz.ch/home/obalcells/a23-jailbreaks-obalcells/experiments/llama2_tl_bug/repro.ipynb#Y140sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m     check_similarity_with_hf_model(tl_model, hf_model, atol\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n",
      "\u001b[1;32m/home/obalcells/a23-jailbreaks-obalcells/experiments/llama2_tl_bug/repro.ipynb Cell 61\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bprivsec0.inf.ethz.ch/home/obalcells/a23-jailbreaks-obalcells/experiments/llama2_tl_bug/repro.ipynb#Y140sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m hf_logits \u001b[39m=\u001b[39m hf_model(tokens\u001b[39m.\u001b[39mto(devices[\u001b[39m0\u001b[39m]))\u001b[39m.\u001b[39mlogits\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bprivsec0.inf.ethz.ch/home/obalcells/a23-jailbreaks-obalcells/experiments/llama2_tl_bug/repro.ipynb#Y140sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m tl_logits \u001b[39m=\u001b[39m tl_model(tokens\u001b[39m.\u001b[39mto(devices[\u001b[39m1\u001b[39m]), prepend_bos\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bprivsec0.inf.ethz.ch/home/obalcells/a23-jailbreaks-obalcells/experiments/llama2_tl_bug/repro.ipynb#Y140sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39massert\u001b[39;00m torch\u001b[39m.\u001b[39mallclose(tl_logits\u001b[39m.\u001b[39mcpu(), hf_logits\u001b[39m.\u001b[39mcpu(), atol\u001b[39m=\u001b[39matol), \u001b[39m\"\u001b[39m\u001b[39mNumerical error too large\u001b[39m\u001b[39m\"\u001b[39m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Numerical error too large"
     ]
    }
   ],
   "source": [
    "# before changing ANYTHING\n",
    "with torch.no_grad():\n",
    "    check_similarity_with_hf_model(tl_model, hf_model, atol=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in range(32):\n",
    "    tl_model.blocks[layer].ln1 = layer_norms[layer][0].to(devices[1])\n",
    "    tl_model.blocks[layer].ln2 = layer_norms[layer][1].to(devices[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Numerical error too large",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/obalcells/a23-jailbreaks-obalcells/experiments/llama2_tl_bug/repro.ipynb Cell 63\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bprivsec0.inf.ethz.ch/home/obalcells/a23-jailbreaks-obalcells/experiments/llama2_tl_bug/repro.ipynb#Y136sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# before running this we've replaced ln1 and ln2 at each layer with the corresponding ln in the HF model\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bprivsec0.inf.ethz.ch/home/obalcells/a23-jailbreaks-obalcells/experiments/llama2_tl_bug/repro.ipynb#Y136sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bprivsec0.inf.ethz.ch/home/obalcells/a23-jailbreaks-obalcells/experiments/llama2_tl_bug/repro.ipynb#Y136sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m     check_similarity_with_hf_model(tl_model, hf_model, atol\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n",
      "\u001b[1;32m/home/obalcells/a23-jailbreaks-obalcells/experiments/llama2_tl_bug/repro.ipynb Cell 63\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bprivsec0.inf.ethz.ch/home/obalcells/a23-jailbreaks-obalcells/experiments/llama2_tl_bug/repro.ipynb#Y136sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m hf_logits \u001b[39m=\u001b[39m hf_model(tokens\u001b[39m.\u001b[39mto(devices[\u001b[39m0\u001b[39m]))\u001b[39m.\u001b[39mlogits\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bprivsec0.inf.ethz.ch/home/obalcells/a23-jailbreaks-obalcells/experiments/llama2_tl_bug/repro.ipynb#Y136sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m tl_logits \u001b[39m=\u001b[39m tl_model(tokens\u001b[39m.\u001b[39mto(devices[\u001b[39m1\u001b[39m]), prepend_bos\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bprivsec0.inf.ethz.ch/home/obalcells/a23-jailbreaks-obalcells/experiments/llama2_tl_bug/repro.ipynb#Y136sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39massert\u001b[39;00m torch\u001b[39m.\u001b[39mallclose(tl_logits\u001b[39m.\u001b[39mcpu(), hf_logits\u001b[39m.\u001b[39mcpu(), atol\u001b[39m=\u001b[39matol), \u001b[39m\"\u001b[39m\u001b[39mNumerical error too large\u001b[39m\u001b[39m\"\u001b[39m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Numerical error too large"
     ]
    }
   ],
   "source": [
    "# before running this we've replaced ln1 and ln2 at each layer with the corresponding ln in the HF model\n",
    "with torch.no_grad():\n",
    "    check_similarity_with_hf_model(tl_model, hf_model, atol=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1e-05\n",
      "1e-05\n"
     ]
    }
   ],
   "source": [
    "print(hf_model.model.layers[10].input_layernorm.variance_epsilon)\n",
    "print(hf_model.model.layers[10].post_attention_layernorm.variance_epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1e-06\n",
      "1e-06\n"
     ]
    }
   ],
   "source": [
    "print(tl_model.blocks[10].ln1.eps)\n",
    "print(tl_model.blocks[10].ln2.eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_norms_new_eps = []\n",
    "for layer in range(32):\n",
    "    ln1 = RMSNorm(tl_model.cfg, length=tl_model.cfg.d_model)\n",
    "    ln2 = RMSNorm(tl_model.cfg, length=tl_model.cfg.d_model)\n",
    "    ln1.w = torch.nn.Parameter(hf_model.model.layers[layer].input_layernorm.weight.clone())\n",
    "    ln2.w = torch.nn.Parameter(hf_model.model.layers[layer].post_attention_layernorm.weight.clone())\n",
    "    ln1.eps = 1e-5\n",
    "    ln2.eps = 1e-5\n",
    "    lns = [ln1, ln2]\n",
    "    layer_norms_new_eps.append(lns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in range(32):\n",
    "    tl_model.blocks[layer].ln1 = layer_norms_new_eps[layer][0].to(devices[1])\n",
    "    tl_model.blocks[layer].ln2 = layer_norms_new_eps[layer][1].to(devices[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# before running this we've replaced ln1 and ln2 at each layer with the corresponding ln in the HF model\n",
    "with torch.no_grad():\n",
    "    check_similarity_with_hf_model(tl_model, hf_model, atol=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Numerical error too large",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/obalcells/a23-jailbreaks-obalcells/experiments/llama2_tl_bug/repro.ipynb Cell 68\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bprivsec0.inf.ethz.ch/home/obalcells/a23-jailbreaks-obalcells/experiments/llama2_tl_bug/repro.ipynb#Y146sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# before running this we've replaced ln1 and ln2 at each layer with the corresponding ln in the HF model\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bprivsec0.inf.ethz.ch/home/obalcells/a23-jailbreaks-obalcells/experiments/llama2_tl_bug/repro.ipynb#Y146sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bprivsec0.inf.ethz.ch/home/obalcells/a23-jailbreaks-obalcells/experiments/llama2_tl_bug/repro.ipynb#Y146sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m     check_similarity_with_hf_model(tl_model, hf_model, atol\u001b[39m=\u001b[39;49m\u001b[39m0.00001\u001b[39;49m)\n",
      "\u001b[1;32m/home/obalcells/a23-jailbreaks-obalcells/experiments/llama2_tl_bug/repro.ipynb Cell 68\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bprivsec0.inf.ethz.ch/home/obalcells/a23-jailbreaks-obalcells/experiments/llama2_tl_bug/repro.ipynb#Y146sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m hf_logits \u001b[39m=\u001b[39m hf_model(tokens\u001b[39m.\u001b[39mto(devices[\u001b[39m0\u001b[39m]))\u001b[39m.\u001b[39mlogits\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bprivsec0.inf.ethz.ch/home/obalcells/a23-jailbreaks-obalcells/experiments/llama2_tl_bug/repro.ipynb#Y146sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m tl_logits \u001b[39m=\u001b[39m tl_model(tokens\u001b[39m.\u001b[39mto(devices[\u001b[39m1\u001b[39m]), prepend_bos\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bprivsec0.inf.ethz.ch/home/obalcells/a23-jailbreaks-obalcells/experiments/llama2_tl_bug/repro.ipynb#Y146sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39massert\u001b[39;00m torch\u001b[39m.\u001b[39mallclose(tl_logits\u001b[39m.\u001b[39mcpu(), hf_logits\u001b[39m.\u001b[39mcpu(), atol\u001b[39m=\u001b[39matol), \u001b[39m\"\u001b[39m\u001b[39mNumerical error too large\u001b[39m\u001b[39m\"\u001b[39m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Numerical error too large"
     ]
    }
   ],
   "source": [
    "# before running this we've replaced ln1 and ln2 at each layer with the corresponding ln in the HF model\n",
    "with torch.no_grad():\n",
    "    check_similarity_with_hf_model(tl_model, hf_model, atol=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RMSNormChangedEps(nn.Module):\n",
    "    def __init__(\n",
    "        self, cfg: Union[Dict, HookedTransformerConfig], length: Optional[int] = None\n",
    "    ):\n",
    "        \"\"\"\n",
    "        RMSNorm - LayerNorm without the centering and bias (RMS = Root Mean Square)\n",
    "\n",
    "        length (Optional[int]): If the dimension of the RMSNorm. If not provided, assumed to be d_model\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        if isinstance(cfg, Dict):\n",
    "            cfg = HookedTransformerConfig.from_dict(cfg)\n",
    "        self.cfg = cfg\n",
    "        self.eps = self.cfg.eps\n",
    "        if length is None:\n",
    "            self.length = self.cfg.d_model\n",
    "        else:\n",
    "            self.length = length\n",
    "\n",
    "        self.w = nn.Parameter(torch.ones(self.length, dtype=cfg.dtype))\n",
    "\n",
    "        # Adds a hook point for the normalisation scale factor\n",
    "        self.hook_scale = HookPoint()  # [batch, pos, 1]\n",
    "        self.hook_normalized = HookPoint()  # [batch, pos, length]\n",
    "\n",
    "    def forward(\n",
    "        self, x: Float[torch.Tensor, \"batch pos length\"]\n",
    "    ) -> Float[torch.Tensor, \"batch pos length\"]:\n",
    "        if self.cfg.dtype not in [torch.float32, torch.float64]:\n",
    "            x = x.to(torch.float32)\n",
    "\n",
    "        scale: Float[torch.Tensor, \"batch pos 1\"] = self.hook_scale(\n",
    "            (x.pow(2).mean(-1, keepdim=True) + self.eps).sqrt()\n",
    "        )\n",
    "        x = self.hook_normalized(x / scale).to(self.cfg.dtype)  # [batch, pos, length]\n",
    "        return x * self.w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_norms_changed_eps = []\n",
    "\n",
    "for layer in range(32):\n",
    "    ln1 = RMSNormChangedEps(tl_model.cfg, length=tl_model.cfg.d_model)\n",
    "    ln2 = RMSNormChangedEps(tl_model.cfg, length=tl_model.cfg.d_model)\n",
    "    ln1.w = torch.nn.Parameter(hf_model.model.layers[layer].input_layernorm.weight.clone())\n",
    "    ln2.w = torch.nn.Parameter(hf_model.model.layers[layer].post_attention_layernorm.weight.clone())\n",
    "    ln1.eps = 1e-5\n",
    "    ln2.eps = 1e-5\n",
    "    lns = [ln1, ln2]\n",
    "    layer_norms_changed_eps.append(lns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in range(32):\n",
    "    tl_model.blocks[layer].ln1 = layer_norms_changed_eps[layer][0].to(devices[1])\n",
    "    tl_model.blocks[layer].ln2 = layer_norms_changed_eps[layer][1].to(devices[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# before running this we've replaced ln1 and ln2 at each layer with the corresponding ln in the HF model\n",
    "with torch.no_grad():\n",
    "    check_similarity_with_hf_model(tl_model, hf_model, atol=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in range(32):\n",
    "    tl_model.blocks[layer].ln1 = layer_norms_changed_eps[layer][0].to(devices[1])\n",
    "    tl_model.blocks[layer].ln2 = layer_norms_changed_eps[layer][1].to(devices[1])\n",
    "    tl_model.blocks[layer].ln1.eps = 1e-6\n",
    "    tl_model.blocks[layer].ln2.eps = 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Numerical error too large",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/obalcells/a23-jailbreaks-obalcells/experiments/llama2_tl_bug/repro.ipynb Cell 75\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bprivsec0.inf.ethz.ch/home/obalcells/a23-jailbreaks-obalcells/experiments/llama2_tl_bug/repro.ipynb#Y163sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# before running this we've replaced ln1 and ln2 at each layer with the corresponding ln in the HF model\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bprivsec0.inf.ethz.ch/home/obalcells/a23-jailbreaks-obalcells/experiments/llama2_tl_bug/repro.ipynb#Y163sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bprivsec0.inf.ethz.ch/home/obalcells/a23-jailbreaks-obalcells/experiments/llama2_tl_bug/repro.ipynb#Y163sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m     check_similarity_with_hf_model(tl_model, hf_model, atol\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n",
      "\u001b[1;32m/home/obalcells/a23-jailbreaks-obalcells/experiments/llama2_tl_bug/repro.ipynb Cell 75\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bprivsec0.inf.ethz.ch/home/obalcells/a23-jailbreaks-obalcells/experiments/llama2_tl_bug/repro.ipynb#Y163sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m hf_logits \u001b[39m=\u001b[39m hf_model(tokens\u001b[39m.\u001b[39mto(devices[\u001b[39m0\u001b[39m]))\u001b[39m.\u001b[39mlogits\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bprivsec0.inf.ethz.ch/home/obalcells/a23-jailbreaks-obalcells/experiments/llama2_tl_bug/repro.ipynb#Y163sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m tl_logits \u001b[39m=\u001b[39m tl_model(tokens\u001b[39m.\u001b[39mto(devices[\u001b[39m1\u001b[39m]), prepend_bos\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bprivsec0.inf.ethz.ch/home/obalcells/a23-jailbreaks-obalcells/experiments/llama2_tl_bug/repro.ipynb#Y163sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39massert\u001b[39;00m torch\u001b[39m.\u001b[39mallclose(tl_logits\u001b[39m.\u001b[39mcpu(), hf_logits\u001b[39m.\u001b[39mcpu(), atol\u001b[39m=\u001b[39matol), \u001b[39m\"\u001b[39m\u001b[39mNumerical error too large\u001b[39m\u001b[39m\"\u001b[39m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Numerical error too large"
     ]
    }
   ],
   "source": [
    "# before running this we've replaced ln1 and ln2 at each layer with the corresponding ln in the HF model\n",
    "with torch.no_grad():\n",
    "    check_similarity_with_hf_model(tl_model, hf_model, atol=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change the TL config to have `eps=1e-5`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "del tl_model\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f031879081c446f39d5aeb7ed07287c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 172.00 MiB. GPU 1 has a total capacty of 47.54 GiB of which 88.25 MiB is free. Including non-PyTorch memory, this process has 47.43 GiB memory in use. Of the allocated memory 47.11 GiB is allocated by PyTorch, and 20.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m/home/obalcells/a23-jailbreaks-obalcells/experiments/llama2_tl_bug/repro.ipynb Cell 78\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bprivsec0.inf.ethz.ch/home/obalcells/a23-jailbreaks-obalcells/experiments/llama2_tl_bug/repro.ipynb#Y200sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m tl_model \u001b[39m=\u001b[39m HookedTransformer\u001b[39m.\u001b[39;49mfrom_pretrained(\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bprivsec0.inf.ethz.ch/home/obalcells/a23-jailbreaks-obalcells/experiments/llama2_tl_bug/repro.ipynb#Y200sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m     MODEL_NAME,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bprivsec0.inf.ethz.ch/home/obalcells/a23-jailbreaks-obalcells/experiments/llama2_tl_bug/repro.ipynb#Y200sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m     hf_model\u001b[39m=\u001b[39;49mAutoModelForCausalLM\u001b[39m.\u001b[39;49mfrom_pretrained(\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bprivsec0.inf.ethz.ch/home/obalcells/a23-jailbreaks-obalcells/experiments/llama2_tl_bug/repro.ipynb#Y200sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m         MODEL_NAME,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bprivsec0.inf.ethz.ch/home/obalcells/a23-jailbreaks-obalcells/experiments/llama2_tl_bug/repro.ipynb#Y200sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m         low_cpu_mem_usage\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bprivsec0.inf.ethz.ch/home/obalcells/a23-jailbreaks-obalcells/experiments/llama2_tl_bug/repro.ipynb#Y200sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m         torch_dtype\u001b[39m=\u001b[39;49mtorch\u001b[39m.\u001b[39;49mfloat32,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bprivsec0.inf.ethz.ch/home/obalcells/a23-jailbreaks-obalcells/experiments/llama2_tl_bug/repro.ipynb#Y200sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m     ),\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bprivsec0.inf.ethz.ch/home/obalcells/a23-jailbreaks-obalcells/experiments/llama2_tl_bug/repro.ipynb#Y200sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m     tokenizer\u001b[39m=\u001b[39;49mAutoTokenizer\u001b[39m.\u001b[39;49mfrom_pretrained(MODEL_NAME),\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bprivsec0.inf.ethz.ch/home/obalcells/a23-jailbreaks-obalcells/experiments/llama2_tl_bug/repro.ipynb#Y200sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m     device\u001b[39m=\u001b[39;49mdevices[\u001b[39m1\u001b[39;49m],\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bprivsec0.inf.ethz.ch/home/obalcells/a23-jailbreaks-obalcells/experiments/llama2_tl_bug/repro.ipynb#Y200sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m     n_devices\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bprivsec0.inf.ethz.ch/home/obalcells/a23-jailbreaks-obalcells/experiments/llama2_tl_bug/repro.ipynb#Y200sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m     move_to_device\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bprivsec0.inf.ethz.ch/home/obalcells/a23-jailbreaks-obalcells/experiments/llama2_tl_bug/repro.ipynb#Y200sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m     fold_ln\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bprivsec0.inf.ethz.ch/home/obalcells/a23-jailbreaks-obalcells/experiments/llama2_tl_bug/repro.ipynb#Y200sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m     fold_value_biases\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bprivsec0.inf.ethz.ch/home/obalcells/a23-jailbreaks-obalcells/experiments/llama2_tl_bug/repro.ipynb#Y200sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m     center_writing_weights\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bprivsec0.inf.ethz.ch/home/obalcells/a23-jailbreaks-obalcells/experiments/llama2_tl_bug/repro.ipynb#Y200sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m     center_unembed\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bprivsec0.inf.ethz.ch/home/obalcells/a23-jailbreaks-obalcells/experiments/llama2_tl_bug/repro.ipynb#Y200sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m     torch_dtype\u001b[39m=\u001b[39;49mtorch\u001b[39m.\u001b[39;49mfloat32,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bprivsec0.inf.ethz.ch/home/obalcells/a23-jailbreaks-obalcells/experiments/llama2_tl_bug/repro.ipynb#Y200sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m )\n",
      "File \u001b[0;32m/local/home/obalcells/miniforge3/envs/jailbreak/lib/python3.11/site-packages/transformer_lens/HookedTransformer.py:1304\u001b[0m, in \u001b[0;36mHookedTransformer.from_pretrained\u001b[0;34m(cls, model_name, fold_ln, center_writing_weights, center_unembed, refactor_factored_attn_matrices, checkpoint_index, checkpoint_value, hf_model, device, n_devices, tokenizer, move_to_device, fold_value_biases, default_prepend_bos, default_padding_side, dtype, **from_pretrained_kwargs)\u001b[0m\n\u001b[1;32m   1294\u001b[0m model\u001b[39m.\u001b[39mload_and_process_state_dict(\n\u001b[1;32m   1295\u001b[0m     state_dict,\n\u001b[1;32m   1296\u001b[0m     fold_ln\u001b[39m=\u001b[39mfold_ln,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1300\u001b[0m     refactor_factored_attn_matrices\u001b[39m=\u001b[39mrefactor_factored_attn_matrices,\n\u001b[1;32m   1301\u001b[0m )\n\u001b[1;32m   1303\u001b[0m \u001b[39mif\u001b[39;00m move_to_device:\n\u001b[0;32m-> 1304\u001b[0m     model\u001b[39m.\u001b[39;49mmove_model_modules_to_device()\n\u001b[1;32m   1306\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mLoaded pretrained model \u001b[39m\u001b[39m{\u001b[39;00mmodel_name\u001b[39m}\u001b[39;00m\u001b[39m into HookedTransformer\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1308\u001b[0m \u001b[39mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m/local/home/obalcells/miniforge3/envs/jailbreak/lib/python3.11/site-packages/transformer_lens/HookedTransformer.py:1065\u001b[0m, in \u001b[0;36mHookedTransformer.move_model_modules_to_device\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1061\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39munembed\u001b[39m.\u001b[39mto(\n\u001b[1;32m   1062\u001b[0m     devices\u001b[39m.\u001b[39mget_device_for_block_index(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcfg\u001b[39m.\u001b[39mn_layers \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcfg)\n\u001b[1;32m   1063\u001b[0m )\n\u001b[1;32m   1064\u001b[0m \u001b[39mfor\u001b[39;00m i, block \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mblocks):\n\u001b[0;32m-> 1065\u001b[0m     block\u001b[39m.\u001b[39;49mto(devices\u001b[39m.\u001b[39;49mget_device_for_block_index(i, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcfg))\n",
      "File \u001b[0;32m/local/home/obalcells/miniforge3/envs/jailbreak/lib/python3.11/site-packages/torch/nn/modules/module.py:1160\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1156\u001b[0m         \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   1157\u001b[0m                     non_blocking, memory_format\u001b[39m=\u001b[39mconvert_to_format)\n\u001b[1;32m   1158\u001b[0m     \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m, non_blocking)\n\u001b[0;32m-> 1160\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_apply(convert)\n",
      "File \u001b[0;32m/local/home/obalcells/miniforge3/envs/jailbreak/lib/python3.11/site-packages/torch/nn/modules/module.py:810\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    808\u001b[0m \u001b[39mif\u001b[39;00m recurse:\n\u001b[1;32m    809\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[0;32m--> 810\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[1;32m    812\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    813\u001b[0m     \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    814\u001b[0m         \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    815\u001b[0m         \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    820\u001b[0m         \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    821\u001b[0m         \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m/local/home/obalcells/miniforge3/envs/jailbreak/lib/python3.11/site-packages/torch/nn/modules/module.py:833\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    829\u001b[0m \u001b[39m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    830\u001b[0m \u001b[39m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    831\u001b[0m \u001b[39m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    832\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m--> 833\u001b[0m     param_applied \u001b[39m=\u001b[39m fn(param)\n\u001b[1;32m    834\u001b[0m should_use_set_data \u001b[39m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    835\u001b[0m \u001b[39mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[0;32m/local/home/obalcells/miniforge3/envs/jailbreak/lib/python3.11/site-packages/torch/nn/modules/module.py:1158\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1155\u001b[0m \u001b[39mif\u001b[39;00m convert_to_format \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m t\u001b[39m.\u001b[39mdim() \u001b[39min\u001b[39;00m (\u001b[39m4\u001b[39m, \u001b[39m5\u001b[39m):\n\u001b[1;32m   1156\u001b[0m     \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   1157\u001b[0m                 non_blocking, memory_format\u001b[39m=\u001b[39mconvert_to_format)\n\u001b[0;32m-> 1158\u001b[0m \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39;49mto(device, dtype \u001b[39mif\u001b[39;49;00m t\u001b[39m.\u001b[39;49mis_floating_point() \u001b[39mor\u001b[39;49;00m t\u001b[39m.\u001b[39;49mis_complex() \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m, non_blocking)\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 172.00 MiB. GPU 1 has a total capacty of 47.54 GiB of which 88.25 MiB is free. Including non-PyTorch memory, this process has 47.43 GiB memory in use. Of the allocated memory 47.11 GiB is allocated by PyTorch, and 20.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "tl_model = HookedTransformer.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    hf_model=AutoModelForCausalLM.from_pretrained(\n",
    "        MODEL_NAME,\n",
    "        low_cpu_mem_usage=True,\n",
    "        torch_dtype=torch.float32,\n",
    "    ),\n",
    "    tokenizer=AutoTokenizer.from_pretrained(MODEL_NAME),\n",
    "    device=devices[1],\n",
    "    n_devices=1,\n",
    "    move_to_device=True,\n",
    "    fold_ln=False,\n",
    "    fold_value_biases=False,\n",
    "    center_writing_weights=False,\n",
    "    center_unembed=False,\n",
    "    torch_dtype=torch.float32,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jailbreak",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
